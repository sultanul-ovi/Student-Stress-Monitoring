{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf92030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634141d8",
   "metadata": {},
   "source": [
    "## ML Model Results Storage Framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441da7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results storage framework loaded successfully!\n",
      "Available functions:\n",
      "- storeResults(model, config, accuracy, f1, recall, precision, auc_roc)\n",
      "- displayAndSaveResults(filename_prefix='model_results')\n",
      "- clearResults()\n",
      "- plotModelComparison(result_df)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ML MODEL RESULTS STORAGE FRAMEWORK\n",
    "# =============================================================================\n",
    "\n",
    "# Creating holders to store the model performance results\n",
    "ML_Model = []\n",
    "ML_Config = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "auc_roc = []  # Adding a holder for AUC-ROC\n",
    "\n",
    "# Function to call for storing the results\n",
    "def storeResults(model, config, a, b, c, d, e):\n",
    "    \"\"\"\n",
    "    Store model performance results\n",
    "    \n",
    "    Parameters:\n",
    "    model: Name of the ML model\n",
    "    config: Configuration name (preprocessing steps applied)\n",
    "    a: Accuracy score\n",
    "    b: F1 score\n",
    "    c: Recall score\n",
    "    d: Precision score\n",
    "    e: AUC-ROC score\n",
    "    \"\"\"\n",
    "    ML_Model.append(model)\n",
    "    ML_Config.append(config)\n",
    "    accuracy.append(round(a, 6))\n",
    "    f1_score.append(round(b, 6))\n",
    "    recall.append(round(c, 6))\n",
    "    precision.append(round(d, 6))\n",
    "    auc_roc.append(round(e, 6))\n",
    "\n",
    "# Function to display and save results\n",
    "def displayAndSaveResults(filename_prefix='model_results'):\n",
    "    \"\"\"\n",
    "    Create dataframe from results, display, and save to CSV\n",
    "    \n",
    "    Parameters:\n",
    "    filename_prefix: Prefix for the CSV filenames\n",
    "    \"\"\"\n",
    "    # Creating the dataframe\n",
    "    result = pd.DataFrame({\n",
    "        'ML Model': ML_Model,\n",
    "        'Configuration': ML_Config,\n",
    "        'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "        'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "        'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "        'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "        'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "    })\n",
    "    \n",
    "    # Remove duplicates if any\n",
    "    result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL PERFORMANCE RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    print(result.to_string(index=False))\n",
    "    \n",
    "    # Saving the result to a CSV file\n",
    "    result.to_csv(f'{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nResults saved to {filename_prefix}.csv\")\n",
    "    \n",
    "    # Sorting the dataframe on accuracy and F1 Score\n",
    "    sorted_result = result.sort_values(by=['Accuracy', 'F1 Score'], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "    print(\"=\"*100)\n",
    "    print(sorted_result.to_string(index=False))\n",
    "    \n",
    "    # Saving the sorted result to a CSV file\n",
    "    sorted_result.to_csv(f'sorted_{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nSorted results saved to sorted_{filename_prefix}.csv\")\n",
    "    \n",
    "    return result, sorted_result\n",
    "\n",
    "# Function to clear results (useful when running multiple experiments)\n",
    "def clearResults():\n",
    "    \"\"\"Clear all stored results\"\"\"\n",
    "    global ML_Model, ML_Config, accuracy, f1_score, recall, precision, auc_roc\n",
    "    ML_Model.clear()\n",
    "    ML_Config.clear()\n",
    "    accuracy.clear()\n",
    "    f1_score.clear()\n",
    "    recall.clear()\n",
    "    precision.clear()\n",
    "    auc_roc.clear()\n",
    "    print(\"Results cleared!\")\n",
    "\n",
    "# Function to plot model comparison\n",
    "def plotModelComparison(result_df):\n",
    "    \"\"\"\n",
    "    Create visualization comparing model performances\n",
    "    \n",
    "    Parameters:\n",
    "    result_df: DataFrame with model results\n",
    "    \"\"\"\n",
    "    # Convert percentage strings back to floats for plotting\n",
    "    metrics_cols = ['Accuracy', 'F1 Score', 'Recall', 'Precision', 'ROC_AUC']\n",
    "    plot_df = result_df.copy()\n",
    "    \n",
    "    for col in metrics_cols:\n",
    "        plot_df[col] = plot_df[col].str.rstrip('%').astype(float)\n",
    "    \n",
    "    # Create subplot for each metric\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_cols):\n",
    "        # Group by model and get mean performance across configurations\n",
    "        model_performance = plot_df.groupby('ML Model')[metric].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Create bar plot\n",
    "        ax = axes[idx]\n",
    "        bars = ax.bar(range(len(model_performance)), model_performance.values, \n",
    "                      color=plt.cm.Blues(np.linspace(0.4, 0.9, len(model_performance))))\n",
    "        ax.set_xticks(range(len(model_performance)))\n",
    "        ax.set_xticklabels(model_performance.index, rotation=45, ha='right')\n",
    "        ax.set_ylabel(f'{metric} (%)')\n",
    "        ax.set_title(f'Average {metric} by Model', fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Hide the last subplot if we have 5 metrics\n",
    "    if len(metrics_cols) == 5:\n",
    "        axes[5].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Model results storage framework loaded successfully!\")\n",
    "print(\"Available functions:\")\n",
    "print(\"- storeResults(model, config, accuracy, f1, recall, precision, auc_roc)\")\n",
    "print(\"- displayAndSaveResults(filename_prefix='model_results')\")\n",
    "print(\"- clearResults()\")\n",
    "print(\"- plotModelComparison(result_df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbb58d",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7152ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 19\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV: 19\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 15\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with Original Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.889697  0.891052 0.889017   0.905546 0.987771\n",
      "    Test  0.901818  0.902583 0.903282   0.910426 0.989531\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 0.1, 'coef0': 0.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Running SVM with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.872727  0.872769 0.872979   0.873092 0.972408\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 1.0, 'degree': 4, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997817\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970436\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with RFECV configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997894\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970422\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.880000  0.881269 0.879410   0.887602 0.925045\n",
      "    Test  0.901818  0.902473 0.902495   0.907805 0.941634\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (assuming you've already loaded it as 'data2')\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a0553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 19\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV: 19\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 11\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with Original Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.889697  0.891052 0.889017   0.905546 0.987824\n",
      "    Test  0.901818  0.902583 0.903282   0.910426 0.989512\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 0.1, 'coef0': 0.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Running SVM with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.872727  0.872769 0.872979   0.873092 0.972556\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 1.0, 'degree': 4, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997868\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970408\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with RFECV configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997676\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970168\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.887273  0.887732 0.887622   0.888524 0.979296\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 10, 'coef0': 0.5, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62bea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 19\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV: 19\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 18\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with Original Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.889697  0.891052 0.889017   0.905546 0.987815\n",
      "    Test  0.901818  0.902583 0.903282   0.910426 0.989513\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 0.1, 'coef0': 0.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Running SVM with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.872727  0.872769 0.872979   0.873092 0.972288\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 1.0, 'degree': 4, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997873\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970805\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with RFECV configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997854\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970182\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.909091  0.909390 0.909065   0.910020 0.977558\n",
      "    Test  0.905455  0.905573 0.905509   0.905671 0.970165\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your dataset (assuming you've already loaded it as 'data2')\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9b27e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d83a026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 3\n",
      "\n",
      "=== RFECV Feature Selection with Random Forest ===\n",
      "Optimal number of features selected by RFECV: 3\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 3\n",
      "\n",
      "=== Random Forest Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Random Forest with Original Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.883636  0.883696 0.883949   0.884736 0.986966\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
      "Training      1.00  1.000000 1.00000    1.00000  1.00000\n",
      "    Test      0.88  0.880139 0.88044    0.88149  0.98701\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956532 0.956301   0.957264 0.996029\n",
      "    Test  0.923636  0.923650 0.923561   0.923776 0.979601\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Running Random Forest with RFECV configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956532 0.956301   0.957264 0.996029\n",
      "    Test  0.923636  0.923650 0.923561   0.923776 0.979601\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Running Random Forest with PCA configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956524 0.956247   0.957251 0.994913\n",
      "    Test  0.920000  0.919883 0.920103   0.920267 0.983200\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Random Forest classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=42), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200,300,400],\n",
    "    'max_depth': [10,20,50, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_rf = rf.predict(X_train_cfg)\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_train_rf_proba = rf.predict_proba(X_train_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
    "            metrics.accuracy_score(y_test, y_test_rf),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Random Forest',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a8a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 3\n",
      "\n",
      "=== RFECV Feature Selection with Random Forest ===\n",
      "Optimal number of features selected by RFECV: 3\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 2\n",
      "\n",
      "=== Random Forest Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Random Forest with Original Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.883636  0.883696 0.883949   0.884736 0.986966\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
      "Training      1.00  1.000000 1.00000    1.00000  1.00000\n",
      "    Test      0.88  0.880139 0.88044    0.88149  0.98701\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956532 0.956301   0.957264 0.996029\n",
      "    Test  0.923636  0.923650 0.923561   0.923776 0.979601\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Running Random Forest with RFECV configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956532 0.956301   0.957264 0.996029\n",
      "    Test  0.923636  0.923650 0.923561   0.923776 0.979601\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Running Random Forest with PCA configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.955152  0.955316 0.955127   0.955775 0.995011\n",
      "    Test  0.916364  0.916505 0.916873   0.917298 0.983165\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Random Forest classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=42), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200,300,400],\n",
    "    'max_depth': [10,20,50, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_rf = rf.predict(X_train_cfg)\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_train_rf_proba = rf.predict_proba(X_train_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
    "            metrics.accuracy_score(y_test, y_test_rf),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Random Forest',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45223ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 3\n",
      "\n",
      "=== RFECV Feature Selection with Random Forest ===\n",
      "Optimal number of features selected by RFECV: 3\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 3\n",
      "\n",
      "=== Random Forest Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Random Forest with Original Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.883636  0.883696 0.883949   0.884736 0.986966\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
      "Training      1.00  1.000000 1.00000    1.00000  1.00000\n",
      "    Test      0.88  0.880139 0.88044    0.88149  0.98701\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956532 0.956301   0.957264 0.996029\n",
      "    Test  0.923636  0.923650 0.923561   0.923776 0.979601\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Running Random Forest with RFECV configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956532 0.956301   0.957264 0.996029\n",
      "    Test  0.923636  0.923650 0.923561   0.923776 0.979601\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "Running Random Forest with PCA configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956524 0.956247   0.957251 0.994913\n",
      "    Test  0.920000  0.919883 0.920103   0.920267 0.983200\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Random Forest classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=42), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200,300,400],\n",
    "    'max_depth': [10,20,50, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_rf = rf.predict(X_train_cfg)\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_train_rf_proba = rf.predict_proba(X_train_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
    "            metrics.accuracy_score(y_test, y_test_rf),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Random Forest',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6991cc",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f76c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 4\n",
      "\n",
      "=== RFECV Feature Selection with Gradient Boosting ===\n",
      "Optimal number of features selected by RFECV: 3\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 3\n",
      "\n",
      "=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Gradient Boosting with Original Data configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
      "Training      1.00  1.000000 1.00000   1.000000 1.000000\n",
      "    Test      0.88  0.880218 0.88044   0.880752 0.985223\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000   1.00000 1.000000   1.000000 1.000000\n",
      "    Test  0.887273   0.88732 0.888295   0.887719 0.984412\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.984242  0.984412 0.984222   0.984863 0.998943\n",
      "    Test  0.901818  0.901855 0.902838   0.902718 0.989333\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with RFECV configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956539 0.956355   0.957312 0.996878\n",
      "    Test  0.916364  0.916328 0.916150   0.916611 0.971935\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with PCA configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956581 0.956247   0.957432 0.996889\n",
      "    Test  0.916364  0.916278 0.916150   0.916547 0.974927\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Gradient Boosting classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(GradientBoostingClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=gbc_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 200,500],\n",
    "    'max_depth': [3, 5,7,9,15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_gbc = gbc.predict(X_train_cfg)\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_train_gbc_proba = gbc.predict_proba(X_train_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_gbc),\n",
    "            metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gbc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nGradient Boosting Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Gradient Boosting',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76b808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 4\n",
      "\n",
      "=== RFECV Feature Selection with Gradient Boosting ===\n",
      "Optimal number of features selected by RFECV: 4\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 3\n",
      "\n",
      "=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Gradient Boosting with Original Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training      1.00  1.000000 1.000000   1.000000 1.000000\n",
      "    Test      0.88  0.880019 0.880834   0.880694 0.985595\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.883636  0.883707 0.884672   0.884048 0.986823\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.983030  0.983122 0.982981   0.983376 0.998995\n",
      "    Test  0.909091  0.909134 0.910249   0.911002 0.987409\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with RFECV configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.967273  0.967449 0.967283   0.967815 0.996824\n",
      "    Test  0.894545  0.894797 0.895985   0.898764 0.989924\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with PCA configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.962424  0.962633 0.962028   0.964245 0.995562\n",
      "    Test  0.901818  0.902098 0.902216   0.904537 0.986104\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Gradient Boosting classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(GradientBoostingClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=gbc_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 200,500],\n",
    "    'max_depth': [3, 5,7,9,15, 21],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_gbc = gbc.predict(X_train_cfg)\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_train_gbc_proba = gbc.predict_proba(X_train_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_gbc),\n",
    "            metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gbc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nGradient Boosting Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Gradient Boosting',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e62c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 4\n",
      "\n",
      "=== RFECV Feature Selection with Gradient Boosting ===\n",
      "Optimal number of features selected by RFECV: 3\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 3\n",
      "\n",
      "=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Gradient Boosting with Original Data configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.887273  0.887285 0.888295   0.887793 0.986046\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.00000   1.000000  1.00000\n",
      "    Test  0.887273  0.887283 0.88813   0.887706  0.98547\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.969697  0.969951 0.969668   0.970498 0.996854\n",
      "    Test  0.898182  0.898241 0.899608   0.900939 0.989102\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with RFECV configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956519 0.956326   0.956910 0.996887\n",
      "    Test  0.920000  0.920075 0.919938   0.920248 0.968731\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with PCA configuration...\n",
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.956364  0.956552 0.956355   0.957288 0.996887\n",
      "    Test  0.909091  0.909084 0.909133   0.909072 0.975652\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Gradient Boosting classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(GradientBoostingClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=gbc_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 200,500],\n",
    "    'max_depth': [3, 5,7,9,15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_gbc = gbc.predict(X_train_cfg)\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_train_gbc_proba = gbc.predict_proba(X_train_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_gbc),\n",
    "            metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gbc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nGradient Boosting Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Gradient Boosting',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33cc31",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45984c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 2\n",
      "\n",
      "=== RFECV Feature Selection with AdaBoost ===\n",
      "Optimal number of features selected by RFECV: 2\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 2\n",
      "\n",
      "=== AdaBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.890909  0.892257 0.890182   0.900780 0.986736\n",
      "    Test  0.890909  0.892099 0.892298   0.902795 0.986599\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.890909  0.892257 0.890182   0.900780 0.986736\n",
      "    Test  0.890909  0.892099 0.892298   0.902795 0.986599\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.901818  0.902783 0.901192   0.910015 0.967250\n",
      "    Test  0.920000  0.920052 0.920826   0.921212 0.967942\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Running AdaBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.901818  0.902783 0.901192   0.910015 0.967250\n",
      "    Test  0.920000  0.920052 0.920826   0.921212 0.967942\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Running AdaBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.898182  0.899747 0.897382    0.91187 0.945945\n",
      "    Test  0.916364  0.916442 0.917761    0.92104 0.968577\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 0.01, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, AdaBoost classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(AdaBoostClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=ab_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(\n",
    "        AdaBoostClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_ab = ab.predict(X_train_cfg)\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_train_ab_proba = ab.predict_proba(X_train_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_ab),\n",
    "            metrics.accuracy_score(y_test, y_test_ab),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nAdaBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'AdaBoost',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75bfc3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 2\n",
      "\n",
      "=== RFECV Feature Selection with AdaBoost ===\n",
      "Optimal number of features selected by RFECV: 2\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 2\n",
      "\n",
      "=== AdaBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.890909  0.892257 0.890182   0.900780 0.986736\n",
      "    Test  0.890909  0.892099 0.892298   0.902795 0.986599\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.872727  0.872673 0.873258   0.872812 0.985439\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Running AdaBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.901818  0.902783 0.901192   0.910015 0.967250\n",
      "    Test  0.920000  0.920052 0.920826   0.921212 0.967942\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Running AdaBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.901818  0.902783 0.901192   0.910015 0.967250\n",
      "    Test  0.920000  0.920052 0.920826   0.921212 0.967942\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Running AdaBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.898182  0.899747 0.897382    0.91187 0.945945\n",
      "    Test  0.916364  0.916442 0.917761    0.92104 0.968577\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 0.01, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, AdaBoost classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(AdaBoostClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=ab_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(\n",
    "        AdaBoostClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_ab = ab.predict(X_train_cfg)\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_train_ab_proba = ab.predict_proba(X_train_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_ab),\n",
    "            metrics.accuracy_score(y_test, y_test_ab),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nAdaBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'AdaBoost',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad31851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 2\n",
      "\n",
      "=== RFECV Feature Selection with AdaBoost ===\n",
      "Optimal number of features selected by RFECV: 2\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 2\n",
      "\n",
      "=== AdaBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.890909  0.892257 0.890182   0.900780 0.986736\n",
      "    Test  0.890909  0.892099 0.892298   0.902795 0.986599\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=1), 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.869091  0.869106 0.869635   0.869127 0.985311\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Running AdaBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.901818  0.902783 0.901192   0.910015 0.967250\n",
      "    Test  0.920000  0.920052 0.920826   0.921212 0.967942\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Running AdaBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.901818  0.902783 0.901192   0.910015 0.967250\n",
      "    Test  0.920000  0.920052 0.920826   0.921212 0.967942\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Running AdaBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.898182  0.899747 0.897382    0.91187 0.945945\n",
      "    Test  0.916364  0.916442 0.917761    0.92104 0.968577\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 0.01, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, AdaBoost classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(AdaBoostClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=ab_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(\n",
    "        AdaBoostClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_ab = ab.predict(X_train_cfg)\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_train_ab_proba = ab.predict_proba(X_train_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_ab),\n",
    "            metrics.accuracy_score(y_test, y_test_ab),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nAdaBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'AdaBoost',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5efcf3f",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61c3cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 2\n",
      "\n",
      "=== RFECV Feature Selection with XGBoost ===\n",
      "Optimal number of features selected by RFECV: 2\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 2\n",
      "\n",
      "=== XGBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running XGBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 4374 candidates, totalling 43740 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.989091  0.989045 0.988910   0.989316 0.999267\n",
      "    Test  0.880000  0.879840 0.879946   0.880147 0.985612\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'gamma': 0, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 1, 'reg_lambda': 2, 'subsample': 1.0}\n",
      "\n",
      "Running XGBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 4374 candidates, totalling 43740 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.989091  0.989045 0.988910   0.989316 0.999267\n",
      "    Test  0.880000  0.879840 0.879946   0.880147 0.985612\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'gamma': 0, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 1, 'reg_lambda': 2, 'subsample': 1.0}\n",
      "\n",
      "Running XGBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 4374 candidates, totalling 43740 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.900606  0.901705 0.899818   0.910419 0.970234\n",
      "    Test  0.916364  0.916340 0.917481   0.918565 0.979998\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 2, 'subsample': 0.8}\n",
      "\n",
      "Running XGBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 4374 candidates, totalling 43740 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.900606  0.901705 0.899818   0.910419 0.970234\n",
      "    Test  0.916364  0.916340 0.917481   0.918565 0.979998\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 2, 'subsample': 0.8}\n",
      "\n",
      "Running XGBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 4374 candidates, totalling 43740 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.898182  0.899463 0.897407   0.909439 0.960081\n",
      "    Test  0.916364  0.916359 0.917761   0.920143 0.977611\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'gamma': 0, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 100, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, XGBoost classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), \n",
    "                            X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=xgb_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_xgb = xgb.predict(X_train_cfg)\n",
    "    y_test_xgb = xgb.predict(X_test_cfg)\n",
    "    y_train_xgb_proba = xgb.predict_proba(X_train_cfg)\n",
    "    y_test_xgb_proba = xgb.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_xgb),\n",
    "            metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_xgb_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nXGBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'XGBoost',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72e496ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 2\n",
      "\n",
      "=== RFECV Feature Selection with XGBoost ===\n",
      "Optimal number of features selected by RFECV: 2\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 2\n",
      "\n",
      "=== XGBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running XGBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 4374 candidates, totalling 43740 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.989091  0.989045 0.988910   0.989316 0.999267\n",
      "    Test  0.880000  0.879840 0.879946   0.880147 0.985612\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'gamma': 0, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 1, 'reg_lambda': 2, 'subsample': 1.0}\n",
      "\n",
      "Running XGBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 4374 candidates, totalling 43740 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRunning XGBoost with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m configuration...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m xgb = GridSearchCV(\n\u001b[32m     84\u001b[39m     XGBClassifier(use_label_encoder=\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric=\u001b[33m'\u001b[39m\u001b[33mmlogloss\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     85\u001b[39m     param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     89\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m y_train_xgb = xgb.predict(X_train_cfg)\n\u001b[32m     93\u001b[39m y_test_xgb = xgb.predict(X_test_cfg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sulta\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, XGBoost classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), \n",
    "                            X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=xgb_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_xgb = xgb.predict(X_train_cfg)\n",
    "    y_test_xgb = xgb.predict(X_test_cfg)\n",
    "    y_train_xgb_proba = xgb.predict_proba(X_train_cfg)\n",
    "    y_test_xgb_proba = xgb.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_xgb),\n",
    "            metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_xgb_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nXGBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'XGBoost',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ovi, 2025-07-07, XGBoost classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), \n",
    "                            X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=xgb_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_xgb = xgb.predict(X_train_cfg)\n",
    "    y_test_xgb = xgb.predict(X_test_cfg)\n",
    "    y_train_xgb_proba = xgb.predict_proba(X_train_cfg)\n",
    "    y_test_xgb_proba = xgb.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_xgb),\n",
    "            metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_xgb_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nXGBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'XGBoost',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f4947",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d922c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ovi, 2025-07-07, LightGBM classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(LGBMClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with LightGBM ===\")\n",
    "lgbm_estimator = LGBMClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=lgbm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=lgbm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: LightGBM + GridSearchCV\n",
    "print(\"\\n=== LightGBM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [-1, 5, 10],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'min_child_samples': [10, 20],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [0, 1]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning LightGBM with {name} configuration...\")\n",
    "    lgbm = GridSearchCV(\n",
    "        LGBMClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    lgbm.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_lgbm = lgbm.predict(X_train_cfg)\n",
    "    y_test_lgbm = lgbm.predict(X_test_cfg)\n",
    "    y_train_lgbm_proba = lgbm.predict_proba(X_train_cfg)\n",
    "    y_test_lgbm_proba = lgbm.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_lgbm),\n",
    "            metrics.accuracy_score(y_test, y_test_lgbm),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_lgbm_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_lgbm_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nLightGBM Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_lgbm_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'LightGBM',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_lgbm),\n",
    "        metrics.f1_score(y_test, y_test_lgbm, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_lgbm, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_lgbm, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(lgbm.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ovi, 2025-07-07, LightGBM classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(LGBMClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with LightGBM ===\")\n",
    "lgbm_estimator = LGBMClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=lgbm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=lgbm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: LightGBM + GridSearchCV\n",
    "print(\"\\n=== LightGBM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [-1, 5, 10],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'min_child_samples': [10, 20],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [0, 1]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning LightGBM with {name} configuration...\")\n",
    "    lgbm = GridSearchCV(\n",
    "        LGBMClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    lgbm.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_lgbm = lgbm.predict(X_train_cfg)\n",
    "    y_test_lgbm = lgbm.predict(X_test_cfg)\n",
    "    y_train_lgbm_proba = lgbm.predict_proba(X_train_cfg)\n",
    "    y_test_lgbm_proba = lgbm.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_lgbm),\n",
    "            metrics.accuracy_score(y_test, y_test_lgbm),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_lgbm_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_lgbm_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nLightGBM Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_lgbm_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'LightGBM',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_lgbm),\n",
    "        metrics.f1_score(y_test, y_test_lgbm, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_lgbm, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_lgbm, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(lgbm.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ovi, 2025-07-07, LightGBM classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(LGBMClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with LightGBM ===\")\n",
    "lgbm_estimator = LGBMClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=lgbm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=lgbm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: LightGBM + GridSearchCV\n",
    "print(\"\\n=== LightGBM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [-1, 5, 10],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'min_child_samples': [10, 20],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [0, 1]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning LightGBM with {name} configuration...\")\n",
    "    lgbm = GridSearchCV(\n",
    "        LGBMClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    lgbm.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_lgbm = lgbm.predict(X_train_cfg)\n",
    "    y_test_lgbm = lgbm.predict(X_test_cfg)\n",
    "    y_train_lgbm_proba = lgbm.predict_proba(X_train_cfg)\n",
    "    y_test_lgbm_proba = lgbm.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_lgbm),\n",
    "            metrics.accuracy_score(y_test, y_test_lgbm),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_lgbm, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_lgbm, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_lgbm_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_lgbm_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nLightGBM Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_lgbm_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'LightGBM',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_lgbm),\n",
    "        metrics.f1_score(y_test, y_test_lgbm, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_lgbm, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_lgbm, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(lgbm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468954d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c19ec0",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc42d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ovi, 2025-07-07, Bagging classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(BaggingClassifier(base_estimator=DecisionTreeClassifier()), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging ===\")\n",
    "bag_estimator = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "rfecv = RFECV(estimator=bag_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=bag_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: BaggingClassifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.6, 0.8, 1.0],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [False],\n",
    "    'base_estimator': [\n",
    "        DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "        DecisionTreeClassifier(max_depth=5, min_samples_split=5),\n",
    "        DecisionTreeClassifier(max_depth=None, min_samples_split=10)\n",
    "    ]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_bag = bag.predict(X_train_cfg)\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_train_bag_proba = bag.predict_proba(X_train_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_bag),\n",
    "            metrics.accuracy_score(y_test, y_test_bag),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_bag_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nBagging Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Bagging',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(bag.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ovi, 2025-07-07, Bagging classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(BaggingClassifier(base_estimator=DecisionTreeClassifier()), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging ===\")\n",
    "bag_estimator = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "rfecv = RFECV(estimator=bag_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=bag_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: BaggingClassifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.6, 0.8, 1.0],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [False],\n",
    "    'base_estimator': [\n",
    "        DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "        DecisionTreeClassifier(max_depth=5, min_samples_split=5),\n",
    "        DecisionTreeClassifier(max_depth=None, min_samples_split=10)\n",
    "    ]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_bag = bag.predict(X_train_cfg)\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_train_bag_proba = bag.predict_proba(X_train_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_bag),\n",
    "            metrics.accuracy_score(y_test, y_test_bag),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_bag_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nBagging Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Bagging',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(bag.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d659e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Ovi, 2025-07-07, Bagging classification with preprocessing and result logging\n",
    "\n",
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(BaggingClassifier(base_estimator=DecisionTreeClassifier()), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging ===\")\n",
    "bag_estimator = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "rfecv = RFECV(estimator=bag_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=bag_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: BaggingClassifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.6, 0.8, 1.0],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [False],\n",
    "    'base_estimator': [\n",
    "        DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "        DecisionTreeClassifier(max_depth=5, min_samples_split=5),\n",
    "        DecisionTreeClassifier(max_depth=None, min_samples_split=10)\n",
    "    ]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_bag = bag.predict(X_train_cfg)\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_train_bag_proba = bag.predict_proba(X_train_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_bag),\n",
    "            metrics.accuracy_score(y_test, y_test_bag),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_bag_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nBagging Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Bagging',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(bag.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
