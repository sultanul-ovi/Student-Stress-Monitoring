{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46073c67",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb398a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af20dae",
   "metadata": {},
   "source": [
    "## ML Model Results Storage Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a95e6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results storage framework loaded successfully!\n",
      "Available functions:\n",
      "- storeResults(model, config, accuracy, f1, recall, precision, auc_roc)\n",
      "- displayAndSaveResults(filename_prefix='model_results')\n",
      "- clearResults()\n",
      "- plotModelComparison(result_df)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ML MODEL RESULTS STORAGE FRAMEWORK\n",
    "# =============================================================================\n",
    "\n",
    "# Creating holders to store the model performance results\n",
    "ML_Model = []\n",
    "ML_Config = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "auc_roc = []  # Adding a holder for AUC-ROC\n",
    "\n",
    "# Function to call for storing the results\n",
    "def storeResults(model, config, a, b, c, d, e):\n",
    "    \"\"\"\n",
    "    Store model performance results\n",
    "    \n",
    "    Parameters:\n",
    "    model: Name of the ML model\n",
    "    config: Configuration name (preprocessing steps applied)\n",
    "    a: Accuracy score\n",
    "    b: F1 score\n",
    "    c: Recall score\n",
    "    d: Precision score\n",
    "    e: AUC-ROC score\n",
    "    \"\"\"\n",
    "    ML_Model.append(model)\n",
    "    ML_Config.append(config)\n",
    "    accuracy.append(round(a, 6))\n",
    "    f1_score.append(round(b, 6))\n",
    "    recall.append(round(c, 6))\n",
    "    precision.append(round(d, 6))\n",
    "    auc_roc.append(round(e, 6))\n",
    "\n",
    "# Function to display and save results\n",
    "def displayAndSaveResults(filename_prefix='model_results'):\n",
    "    \"\"\"\n",
    "    Create dataframe from results, display, and save to CSV\n",
    "    \n",
    "    Parameters:\n",
    "    filename_prefix: Prefix for the CSV filenames\n",
    "    \"\"\"\n",
    "    # Creating the dataframe\n",
    "    result = pd.DataFrame({\n",
    "        'ML Model': ML_Model,\n",
    "        'Configuration': ML_Config,\n",
    "        'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "        'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "        'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "        'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "        'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "    })\n",
    "    \n",
    "    # Remove duplicates if any\n",
    "    result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL PERFORMANCE RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    print(result.to_string(index=False))\n",
    "    \n",
    "    # Saving the result to a CSV file\n",
    "    result.to_csv(f'{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nResults saved to {filename_prefix}.csv\")\n",
    "    \n",
    "    # Sorting the dataframe on accuracy and F1 Score\n",
    "    sorted_result = result.sort_values(by=['Accuracy', 'F1 Score'], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "    print(\"=\"*100)\n",
    "    print(sorted_result.to_string(index=False))\n",
    "    \n",
    "    # Saving the sorted result to a CSV file\n",
    "    sorted_result.to_csv(f'sorted_{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nSorted results saved to sorted_{filename_prefix}.csv\")\n",
    "    \n",
    "    return result, sorted_result\n",
    "\n",
    "# Function to clear results (useful when running multiple experiments)\n",
    "def clearResults():\n",
    "    \"\"\"Clear all stored results\"\"\"\n",
    "    global ML_Model, ML_Config, accuracy, f1_score, recall, precision, auc_roc\n",
    "    ML_Model.clear()\n",
    "    ML_Config.clear()\n",
    "    accuracy.clear()\n",
    "    f1_score.clear()\n",
    "    recall.clear()\n",
    "    precision.clear()\n",
    "    auc_roc.clear()\n",
    "    print(\"Results cleared!\")\n",
    "\n",
    "# Function to plot model comparison\n",
    "def plotModelComparison(result_df):\n",
    "    \"\"\"\n",
    "    Create visualization comparing model performances\n",
    "    \n",
    "    Parameters:\n",
    "    result_df: DataFrame with model results\n",
    "    \"\"\"\n",
    "    # Convert percentage strings back to floats for plotting\n",
    "    metrics_cols = ['Accuracy', 'F1 Score', 'Recall', 'Precision', 'ROC_AUC']\n",
    "    plot_df = result_df.copy()\n",
    "    \n",
    "    for col in metrics_cols:\n",
    "        plot_df[col] = plot_df[col].str.rstrip('%').astype(float)\n",
    "    \n",
    "    # Create subplot for each metric\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_cols):\n",
    "        # Group by model and get mean performance across configurations\n",
    "        model_performance = plot_df.groupby('ML Model')[metric].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Create bar plot\n",
    "        ax = axes[idx]\n",
    "        bars = ax.bar(range(len(model_performance)), model_performance.values, \n",
    "                      color=plt.cm.Blues(np.linspace(0.4, 0.9, len(model_performance))))\n",
    "        ax.set_xticks(range(len(model_performance)))\n",
    "        ax.set_xticklabels(model_performance.index, rotation=45, ha='right')\n",
    "        ax.set_ylabel(f'{metric} (%)')\n",
    "        ax.set_title(f'Average {metric} by Model', fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Hide the last subplot if we have 5 metrics\n",
    "    if len(metrics_cols) == 5:\n",
    "        axes[5].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Model results storage framework loaded successfully!\")\n",
    "print(\"Available functions:\")\n",
    "print(\"- storeResults(model, config, accuracy, f1, recall, precision, auc_roc)\")\n",
    "print(\"- displayAndSaveResults(filename_prefix='model_results')\")\n",
    "print(\"- clearResults()\")\n",
    "print(\"- plotModelComparison(result_df)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28c6989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress type encoding:\n",
      "  Distress (Negative Stress) - Stress that causes anxiety and impairs well-being.: 0\n",
      "  Eustress (Positive Stress) - Stress that motivates and enhances performance.: 1\n",
      "  No Stress - Currently experiencing minimal to no stress.: 2\n",
      "\n",
      "X.dtypes after processing:\n",
      " Gender                                                                  int64\n",
      "Age                                                                     int64\n",
      "Have you recently experienced stress in your life?                      int64\n",
      "Have you noticed a rapid heartbeat or palpitations?                     int64\n",
      "Have you been dealing with anxiety or tension recently?                 int64\n",
      "Do you face any sleep problems or difficulties falling asleep?          int64\n",
      "Have you been dealing with anxiety or tension recently?.1               int64\n",
      "Have you been getting headaches more often than usual?                  int64\n",
      "Do you get irritated easily?                                            int64\n",
      "Do you have trouble concentrating on your academic tasks?               int64\n",
      "Have you been feeling sadness or low mood?                              int64\n",
      "Have you been experiencing any illness or health issues?                int64\n",
      "Do you often feel lonely or isolated?                                   int64\n",
      "Do you feel overwhelmed with your academic workload?                    int64\n",
      "Are you in competition with your peers, and does it affect you?         int64\n",
      "Do you find that your relationship often causes you stress?             int64\n",
      "Are you facing any difficulties with your professors or instructors?    int64\n",
      "Is your working environment unpleasant or stressful?                    int64\n",
      "Do you struggle to find time for relaxation and leisure activities?     int64\n",
      "Is your hostel or home environment causing you difficulties?            int64\n",
      "Do you lack confidence in your academic performance?                    int64\n",
      "Do you lack confidence in your choice of academic subjects?             int64\n",
      "Academic and extracurricular activities conflicting for you?            int64\n",
      "Do you attend classes regularly?                                        int64\n",
      "Have you gained/lost weight?                                            int64\n",
      "dtype: object\n",
      "\n",
      "Stress type class counts:\n",
      " 0     32\n",
      "1    768\n",
      "2     43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi\n",
    "# 2025-07-22\n",
    "# Load, process and split stress dataset using stress type as target variable\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/Stress_Dataset.csv')\n",
    "\n",
    "# Define target variable (stress type)\n",
    "target_col = 'Which type of stress do you primarily experience?'\n",
    "y = df[target_col]\n",
    "\n",
    "# Separate features (all columns except target)\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Label encode the target variable (stress type)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Print encoding mapping\n",
    "print(\"Stress type encoding:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    print(f\"  {class_name}: {i}\")\n",
    "\n",
    "# Print result info\n",
    "print(\"\\nX.dtypes after processing:\\n\", X.dtypes)\n",
    "print(\"\\nStress type class counts:\\n\", pd.Series(y).value_counts().sort_index())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c849cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892602bb",
   "metadata": {},
   "source": [
    "### SVM with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703b85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 24\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV: 24\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 19\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.992089  0.969245 0.944444   0.997131 0.999583\n",
      "    Test  0.990521  0.964940 0.939394   0.996564 1.000000\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.5, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# Store different configurations\n",
    "configurations = []\n",
    "# configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "# configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "# configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "# configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [100],\n",
    "    'gamma': ['auto'],\n",
    "    'kernel': ['sigmoid'],\n",
    "    'degree': [2],\n",
    "    'coef0': [0.5]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce270e1a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c96ed2",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5784085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 17\n",
      "\n",
      "=== RFECV Feature Selection with Random Forest ===\n",
      "Optimal number of features selected by RFECV: 17\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 16\n",
      "\n",
      "=== Random Forest Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Random Forest with Original Data configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.982734\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.982917\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.962434\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with RFECV configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.962434\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with PCA configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.943128  0.682828 0.579545   0.980392 0.957758\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Random Forest classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=42), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_rf = rf.predict(X_train_cfg)\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_train_rf_proba = rf.predict_proba(X_train_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
    "            metrics.accuracy_score(y_test, y_test_rf),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Random Forest 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16942ac3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0f7b8",
   "metadata": {},
   "source": [
    "### Gradient Boosting with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fe6d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 14\n",
      "\n",
      "=== RFECV Feature Selection with Gradient Boosting ===\n",
      "Optimal number of features selected by RFECV: 14\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 12\n",
      "\n",
      "=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.957346  0.790443 0.693182   0.985075 0.987981\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Gradient Boosting classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "# configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(GradientBoostingClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "# configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=gbc_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "# configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "# configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [500],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_gbc = gbc.predict(X_train_cfg)\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_train_gbc_proba = gbc.predict_proba(X_train_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_gbc),\n",
    "            metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gbc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nGradient Boosting Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Gradient Boosting 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06f7fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad91dc7",
   "metadata": {},
   "source": [
    "### Adaboost with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96e1c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 25\n",
      "\n",
      "=== RFECV Feature Selection with AdaBoost ===\n",
      "Optimal number of features selected by RFECV: 11\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 11\n",
      "\n",
      "=== AdaBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.728044 0.638415   0.935797 0.990141\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, AdaBoost classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "# configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(AdaBoostClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "# configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=ab_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "# configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "# configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [1],\n",
    "    'algorithm': ['SAMME'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(\n",
    "        AdaBoostClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_ab = ab.predict(X_train_cfg)\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_train_ab_proba = ab.predict_proba(X_train_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_ab),\n",
    "            metrics.accuracy_score(y_test, y_test_ab),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nAdaBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'AdaBoost 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911a9a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17717807",
   "metadata": {},
   "source": [
    "### XGBoost with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be3de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 15\n",
      "\n",
      "=== RFECV Feature Selection with XGBoost ===\n",
      "Optimal number of features selected by RFECV: 15\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 14\n",
      "\n",
      "=== XGBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running XGBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.962085  0.820578 0.734848   0.986667 0.955206\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, XGBoost classification with preprocessing and result logging\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "# configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "# configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), \n",
    "                            X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=xgb_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "# configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "# configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3],\n",
    "    'subsample': [0.6],\n",
    "    'min_child_weight': [1]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_xgb = xgb.predict(X_train_cfg)\n",
    "    y_test_xgb = xgb.predict(X_test_cfg)\n",
    "    y_train_xgb_proba = xgb.predict_proba(X_train_cfg)\n",
    "    y_test_xgb_proba = xgb.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_xgb),\n",
    "            metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_xgb_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nXGBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'XGBoost 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78501f2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d444d",
   "metadata": {},
   "source": [
    "### Bagging classification with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066459e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 13\n",
      "\n",
      "=== RFECV Feature Selection with Bagging ===\n",
      "Optimal number of features selected by RFECV: 1\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 1\n",
      "\n",
      "=== Bagging Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Bagging with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.969937  0.860758 0.777778   0.989356 0.998805\n",
      "    Test  0.943128  0.688312 0.590909   0.980392 0.907794\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(min_samples_split=10), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150}\n",
      "\n",
      "Running Bagging with RFECV configuration...\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.911392  0.317881 0.333333   0.303797 0.733710\n",
      "    Test  0.909953  0.317618 0.333333   0.303318 0.712548\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=3), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150}\n",
      "\n",
      "Running Bagging with PCA configuration...\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.911392  0.317881 0.333333   0.303797 0.733733\n",
      "    Test  0.909953  0.317618 0.333333   0.303318 0.712548\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=3), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Bagging classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "# configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "# configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(BaggingClassifier(estimator=DecisionTreeClassifier()), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging ===\")\n",
    "# Use single DecisionTreeClassifier for RFECV to enable feature_importances_\n",
    "tree_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=tree_estimator,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=tree_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: BaggingClassifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [150],\n",
    "    'max_samples': [1.0],\n",
    "    'max_features': [1.0],\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [False],\n",
    "    'estimator': [ \n",
    "        DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "        DecisionTreeClassifier(max_depth=5, min_samples_split=5),\n",
    "        DecisionTreeClassifier(max_depth=None, min_samples_split=10)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_bag = bag.predict(X_train_cfg)\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_train_bag_proba = bag.predict_proba(X_train_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_bag),\n",
    "            metrics.accuracy_score(y_test, y_test_bag),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_bag_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nBagging Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Bagging 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(bag.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfea017",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e24f8f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM Feature Selection Pipeline ===\n",
      "\n",
      "=== SelectKBest Feature Selection for SVM ===\n",
      "Optimal number of features to select using SelectKBest for SVM: 24\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV for SVM: 24\n",
      "\n",
      "=== PCA Dimensionality Reduction for SVM ===\n",
      "Number of components that explain 90.0% variance: 19\n",
      "\n",
      "=== Training Base Models ===\n",
      "\n",
      "Training SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "=== Individual SVM Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.992089  0.969245 0.944444   0.997131 0.999593\n",
      "    Test  0.990521  0.964940 0.939394   0.996564 0.999909\n",
      "\n",
      "Training Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "=== Individual Gradient Boosting Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.957346  0.790443 0.693182   0.985075 0.991636\n",
      "\n",
      "Training AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "\n",
      "=== Individual AdaBoost Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.966825  0.858663 0.793718   0.948181 0.989472\n",
      "\n",
      "=== Voting Classifier (hard) ===\n",
      "\n",
      "Voting Classifier (hard) Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000        0\n",
      "    Test  0.971564  0.873179 0.795455   0.989899        0\n",
      "\n",
      "=== Voting Classifier (soft) ===\n",
      "\n",
      "Voting Classifier (soft) Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000    1.00000 1.000000\n",
      "    Test  0.976303  0.899419 0.837121    0.99154 0.999909\n",
      "\n",
      "=== Voting Classifier (weighted_hard) ===\n",
      "\n",
      "Voting Classifier (weighted_hard) Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.992089  0.969245 0.944444   0.997131        0\n",
      "    Test  0.990521  0.964940 0.939394   0.996564        0\n",
      "\n",
      "=== Voting Classifier (weighted_soft) ===\n",
      "\n",
      "Voting Classifier (weighted_soft) Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.988924   0.95129 0.913194   0.995998 0.999842\n",
      "    Test  0.990521   0.96494 0.939394   0.996564 0.999909\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Voting Classifier with SVM, GB, and AdaBoost\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "# Store different configurations for each model\n",
    "svm_configurations = []\n",
    "gb_configurations = []\n",
    "ab_configurations = []\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# For AdaBoost - uses Original Data\n",
    "ab_configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# For Gradient Boosting - uses Normalized Data\n",
    "gb_configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# SVM Feature Selection Pipeline\n",
    "print(\"\\n=== SVM Feature Selection Pipeline ===\")\n",
    "print(\"\\n=== SelectKBest Feature Selection for SVM ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k_svm = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest for SVM: {optimal_k_svm}\")\n",
    "\n",
    "kbest_svm = SelectKBest(score_func=f_classif, k=optimal_k_svm)\n",
    "X_train_kbest_svm = kbest_svm.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest_svm = kbest_svm.transform(X_test_normalized)\n",
    "\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "rfecv_svm = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv_svm.fit(X_train_kbest_svm, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV for SVM: {rfecv_svm.n_features_}\")\n",
    "\n",
    "rfe_svm = RFE(estimator=svm_estimator, n_features_to_select=rfecv_svm.n_features_)\n",
    "X_train_rfe_svm = rfe_svm.fit_transform(X_train_kbest_svm, y_train)\n",
    "X_test_rfe_svm = rfe_svm.transform(X_test_kbest_svm)\n",
    "\n",
    "print(\"\\n=== PCA Dimensionality Reduction for SVM ===\")\n",
    "pca_svm = PCA().fit(X_train_rfe_svm)\n",
    "cumulative_variance = np.cumsum(pca_svm.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components_svm = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components_svm}')\n",
    "\n",
    "pca_svm = PCA(n_components=n_components_svm)\n",
    "X_train_pca_svm = pca_svm.fit_transform(X_train_rfe_svm)\n",
    "X_test_pca_svm = pca_svm.transform(X_test_rfe_svm)\n",
    "svm_configurations.append(('PCA', X_train_pca_svm, X_test_pca_svm, y_train))\n",
    "\n",
    "# Step 4: Train base models\n",
    "print(\"\\n=== Training Base Models ===\")\n",
    "\n",
    "# SVM parameters\n",
    "svm_param_grid = {\n",
    "    'C': [100],\n",
    "    'gamma': ['auto'],\n",
    "    'kernel': ['sigmoid'],\n",
    "    'degree': [2],\n",
    "    'coef0': [0.5]\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_param_grid = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [500],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ab_param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [1],\n",
    "    'algorithm': ['SAMME'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "# Train SVM\n",
    "print(f\"\\nTraining SVM with PCA configuration...\")\n",
    "svm_grid = GridSearchCV(SVC(probability=True), svm_param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "svm_grid.fit(X_train_pca_svm, y_train)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "\n",
    "# Evaluate individual SVM performance\n",
    "print(\"\\n=== Individual SVM Performance ===\")\n",
    "y_train_svm = best_svm.predict(X_train_pca_svm)\n",
    "y_test_svm = best_svm.predict(X_test_pca_svm)\n",
    "y_train_svm_proba = best_svm.predict_proba(X_train_pca_svm)\n",
    "y_test_svm_proba = best_svm.predict_proba(X_test_pca_svm)\n",
    "\n",
    "svm_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_svm),\n",
    "        metrics.accuracy_score(y_test, y_test_svm),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_svm_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svm_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_svm_metrics = pd.DataFrame(svm_metrics)\n",
    "print(df_svm_metrics.to_string(index=False))\n",
    "storeResults('SVM', 'PCA', \n",
    "    metrics.accuracy_score(y_test, y_test_svm),\n",
    "    metrics.f1_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svm_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Train Gradient Boosting\n",
    "print(f\"\\nTraining Gradient Boosting with Normalized Data configuration...\")\n",
    "gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "gb_grid.fit(X_train_normalized, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "# Evaluate individual GB performance\n",
    "print(\"\\n=== Individual Gradient Boosting Performance ===\")\n",
    "y_train_gb = best_gb.predict(X_train_normalized)\n",
    "y_test_gb = best_gb.predict(X_test_normalized)\n",
    "y_train_gb_proba = best_gb.predict_proba(X_train_normalized)\n",
    "y_test_gb_proba = best_gb.predict_proba(X_test_normalized)\n",
    "\n",
    "gb_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_gb),\n",
    "        metrics.accuracy_score(y_test, y_test_gb),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_gb_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gb_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_gb_metrics = pd.DataFrame(gb_metrics)\n",
    "print(df_gb_metrics.to_string(index=False))\n",
    "storeResults('Gradient Boosting', 'Normalized Data',\n",
    "    metrics.accuracy_score(y_test, y_test_gb),\n",
    "    metrics.f1_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gb_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Train AdaBoost\n",
    "print(f\"\\nTraining AdaBoost with Original Data configuration...\")\n",
    "ab_grid = GridSearchCV(AdaBoostClassifier(), ab_param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "ab_grid.fit(X_train, y_train)\n",
    "best_ab = ab_grid.best_estimator_\n",
    "\n",
    "# Evaluate individual AdaBoost performance\n",
    "print(\"\\n=== Individual AdaBoost Performance ===\")\n",
    "y_train_ab = best_ab.predict(X_train)\n",
    "y_test_ab = best_ab.predict(X_test)\n",
    "y_train_ab_proba = best_ab.predict_proba(X_train)\n",
    "y_test_ab_proba = best_ab.predict_proba(X_test)\n",
    "\n",
    "ab_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_ab),\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_ab_metrics = pd.DataFrame(ab_metrics)\n",
    "print(df_ab_metrics.to_string(index=False))\n",
    "storeResults('AdaBoost', 'Original Data',\n",
    "    metrics.accuracy_score(y_test, y_test_ab),\n",
    "    metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Create voting classifiers with custom approach\n",
    "voting_configs = [\n",
    "    ('hard', 'hard', None),\n",
    "    ('soft', 'soft', None),\n",
    "    ('weighted_hard', 'hard', [0.9, 0.05, 0.05]),\n",
    "    ('weighted_soft', 'soft', [0.9, 0.05, 0.05])\n",
    "]\n",
    "\n",
    "for voting_name, voting_type, weights in voting_configs:\n",
    "    print(f\"\\n=== Voting Classifier ({voting_name}) ===\")\n",
    "    \n",
    "    # Get predictions from each model on their own preprocessed test data\n",
    "    \n",
    "    # SVM predictions on PCA data\n",
    "    svm_test_pred = best_svm.predict(X_test_pca_svm)\n",
    "    svm_test_proba = best_svm.predict_proba(X_test_pca_svm) if voting_type == 'soft' else None\n",
    "    \n",
    "    # GB predictions on normalized data\n",
    "    gb_test_pred = best_gb.predict(X_test_normalized)\n",
    "    gb_test_proba = best_gb.predict_proba(X_test_normalized) if voting_type == 'soft' else None\n",
    "    \n",
    "    # AdaBoost predictions on original data\n",
    "    ab_test_pred = best_ab.predict(X_test)\n",
    "    ab_test_proba = best_ab.predict_proba(X_test) if voting_type == 'soft' else None\n",
    "    \n",
    "    # Also get training predictions for metrics\n",
    "    svm_train_pred = best_svm.predict(X_train_pca_svm)\n",
    "    svm_train_proba = best_svm.predict_proba(X_train_pca_svm) if voting_type == 'soft' else None\n",
    "    \n",
    "    gb_train_pred = best_gb.predict(X_train_normalized)\n",
    "    gb_train_proba = best_gb.predict_proba(X_train_normalized) if voting_type == 'soft' else None\n",
    "    \n",
    "    ab_train_pred = best_ab.predict(X_train)\n",
    "    ab_train_proba = best_ab.predict_proba(X_train) if voting_type == 'soft' else None\n",
    "    \n",
    "    # Combine predictions\n",
    "    if voting_type == 'hard':\n",
    "        # Stack predictions and take weighted/unweighted vote\n",
    "        all_test_preds = np.column_stack([svm_test_pred, gb_test_pred, ab_test_pred])\n",
    "        all_train_preds = np.column_stack([svm_train_pred, gb_train_pred, ab_train_pred])\n",
    "        \n",
    "        if weights:\n",
    "            # Weighted voting\n",
    "            y_test_pred = np.array([np.argmax(np.bincount(row.astype(int), weights=weights)) for row in all_test_preds])\n",
    "            y_train_pred = np.array([np.argmax(np.bincount(row.astype(int), weights=weights)) for row in all_train_preds])\n",
    "        else:\n",
    "            # Simple majority voting\n",
    "            y_test_pred = np.array([np.argmax(np.bincount(row.astype(int))) for row in all_test_preds])\n",
    "            y_train_pred = np.array([np.argmax(np.bincount(row.astype(int))) for row in all_train_preds])\n",
    "        auc_test = 0\n",
    "        auc_train = 0\n",
    "    else:  # soft voting\n",
    "        # Average probabilities\n",
    "        if weights:\n",
    "            y_test_proba = (weights[0] * svm_test_proba + \n",
    "                           weights[1] * gb_test_proba + \n",
    "                           weights[2] * ab_test_proba) / sum(weights)\n",
    "            y_train_proba = (weights[0] * svm_train_proba + \n",
    "                            weights[1] * gb_train_proba + \n",
    "                            weights[2] * ab_train_proba) / sum(weights)\n",
    "        else:\n",
    "            y_test_proba = (svm_test_proba + gb_test_proba + ab_test_proba) / 3\n",
    "            y_train_proba = (svm_train_proba + gb_train_proba + ab_train_proba) / 3\n",
    "            \n",
    "        y_test_pred = np.argmax(y_test_proba, axis=1)\n",
    "        y_train_pred = np.argmax(y_train_proba, axis=1)\n",
    "        \n",
    "        auc_test = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_proba, multi_class='ovr', average='macro')\n",
    "        auc_train = metrics.roc_auc_score(pd.get_dummies(y_train), y_train_proba, multi_class='ovr', average='macro')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train, y_train_pred),\n",
    "            metrics.accuracy_score(y_test, y_test_pred)\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train, y_train_pred, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_pred, average='macro')\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train, y_train_pred, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_pred, average='macro')\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train, y_train_pred, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_pred, average='macro')\n",
    "        ],\n",
    "        \"AUC-ROC\": [auc_train, auc_test]\n",
    "    }\n",
    "    \n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(f\"\\nVoting Classifier ({voting_name}) Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "    \n",
    "    storeResults(\n",
    "        f'Voting Classifier ({voting_name})',\n",
    "        'Mixed Preprocessing',\n",
    "        metrics.accuracy_score(y_test, y_test_pred),\n",
    "        metrics.f1_score(y_test, y_test_pred, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_pred, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_pred, average='macro'),\n",
    "        auc_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28aabfe",
   "metadata": {},
   "source": [
    "# Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d50b12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM Feature Selection Pipeline ===\n",
      "\n",
      "=== SelectKBest Feature Selection for SVM ===\n",
      "Optimal number of features to select using SelectKBest for SVM: 24\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV for SVM: 24\n",
      "\n",
      "=== PCA Dimensionality Reduction for SVM ===\n",
      "Number of components that explain 90.0% variance: 19\n",
      "\n",
      "=== Training Base Models ===\n",
      "\n",
      "Training SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "=== Individual SVM Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.992089  0.969245 0.944444   0.997131 0.999583\n",
      "    Test  0.990521  0.964940 0.939394   0.996564 0.999817\n",
      "\n",
      "Training Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "=== Individual Gradient Boosting Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.962085  0.818235 0.723485   0.986667 0.992128\n",
      "\n",
      "Training AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "\n",
      "=== Individual AdaBoost Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.728044 0.638415   0.935797 0.990141\n",
      "\n",
      "=== Creating Stacking Classifier ===\n",
      "\n",
      "Generating out-of-fold predictions for meta-learner training...\n",
      "\n",
      "Training meta-learner (Logistic Regression)...\n",
      "\n",
      "=== Stacking Classifier Performance ===\n",
      "\n",
      "Stacking Classifier Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.971519  0.872623 0.814236   0.955782 0.993842\n",
      "    Test  0.985782  0.941860 0.897727   0.994872 0.999909\n",
      "\n",
      "=== Trying Alternative Meta-Learners ===\n",
      "\n",
      "Stacking with Random Forest Meta-Learner:\n",
      "Test Accuracy: 1.0000\n",
      "Test F1 Score: 1.0000\n",
      "Test AUC-ROC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Stacking Classifier with SVM, GB, and AdaBoost\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "# Store different configurations for each model\n",
    "svm_configurations = []\n",
    "gb_configurations = []\n",
    "ab_configurations = []\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# For AdaBoost - uses Original Data\n",
    "ab_configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# For Gradient Boosting - uses Normalized Data\n",
    "gb_configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# SVM Feature Selection Pipeline\n",
    "print(\"\\n=== SVM Feature Selection Pipeline ===\")\n",
    "print(\"\\n=== SelectKBest Feature Selection for SVM ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k_svm = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest for SVM: {optimal_k_svm}\")\n",
    "\n",
    "kbest_svm = SelectKBest(score_func=f_classif, k=optimal_k_svm)\n",
    "X_train_kbest_svm = kbest_svm.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest_svm = kbest_svm.transform(X_test_normalized)\n",
    "\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "rfecv_svm = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv_svm.fit(X_train_kbest_svm, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV for SVM: {rfecv_svm.n_features_}\")\n",
    "\n",
    "rfe_svm = RFE(estimator=svm_estimator, n_features_to_select=rfecv_svm.n_features_)\n",
    "X_train_rfe_svm = rfe_svm.fit_transform(X_train_kbest_svm, y_train)\n",
    "X_test_rfe_svm = rfe_svm.transform(X_test_kbest_svm)\n",
    "\n",
    "print(\"\\n=== PCA Dimensionality Reduction for SVM ===\")\n",
    "pca_svm = PCA().fit(X_train_rfe_svm)\n",
    "cumulative_variance = np.cumsum(pca_svm.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components_svm = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components_svm}')\n",
    "\n",
    "pca_svm = PCA(n_components=n_components_svm)\n",
    "X_train_pca_svm = pca_svm.fit_transform(X_train_rfe_svm)\n",
    "X_test_pca_svm = pca_svm.transform(X_test_rfe_svm)\n",
    "svm_configurations.append(('PCA', X_train_pca_svm, X_test_pca_svm, y_train))\n",
    "\n",
    "# Step 4: Train base models\n",
    "print(\"\\n=== Training Base Models ===\")\n",
    "\n",
    "# SVM parameters\n",
    "svm_param_grid = {\n",
    "    'C': [100],\n",
    "    'gamma': ['auto'],\n",
    "    'kernel': ['sigmoid'],\n",
    "    'degree': [2],\n",
    "    'coef0': [0.5]\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_param_grid = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [500],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ab_param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [1],\n",
    "    'algorithm': ['SAMME'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "# Train SVM\n",
    "print(f\"\\nTraining SVM with PCA configuration...\")\n",
    "svm_grid = GridSearchCV(SVC(probability=True), svm_param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "svm_grid.fit(X_train_pca_svm, y_train)\n",
    "best_svm = svm_grid.best_estimator_\n",
    "\n",
    "# Evaluate individual SVM performance\n",
    "print(\"\\n=== Individual SVM Performance ===\")\n",
    "y_train_svm = best_svm.predict(X_train_pca_svm)\n",
    "y_test_svm = best_svm.predict(X_test_pca_svm)\n",
    "y_train_svm_proba = best_svm.predict_proba(X_train_pca_svm)\n",
    "y_test_svm_proba = best_svm.predict_proba(X_test_pca_svm)\n",
    "\n",
    "svm_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_svm),\n",
    "        metrics.accuracy_score(y_test, y_test_svm),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_svm_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svm_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_svm_metrics = pd.DataFrame(svm_metrics)\n",
    "print(df_svm_metrics.to_string(index=False))\n",
    "storeResults('SVM', 'PCA', \n",
    "    metrics.accuracy_score(y_test, y_test_svm),\n",
    "    metrics.f1_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svm_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Train Gradient Boosting\n",
    "print(f\"\\nTraining Gradient Boosting with Normalized Data configuration...\")\n",
    "gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "gb_grid.fit(X_train_normalized, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "\n",
    "# Evaluate individual GB performance\n",
    "print(\"\\n=== Individual Gradient Boosting Performance ===\")\n",
    "y_train_gb = best_gb.predict(X_train_normalized)\n",
    "y_test_gb = best_gb.predict(X_test_normalized)\n",
    "y_train_gb_proba = best_gb.predict_proba(X_train_normalized)\n",
    "y_test_gb_proba = best_gb.predict_proba(X_test_normalized)\n",
    "\n",
    "gb_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_gb),\n",
    "        metrics.accuracy_score(y_test, y_test_gb),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_gb_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gb_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_gb_metrics = pd.DataFrame(gb_metrics)\n",
    "print(df_gb_metrics.to_string(index=False))\n",
    "storeResults('Gradient Boosting', 'Normalized Data',\n",
    "    metrics.accuracy_score(y_test, y_test_gb),\n",
    "    metrics.f1_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gb_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Train AdaBoost\n",
    "print(f\"\\nTraining AdaBoost with Original Data configuration...\")\n",
    "ab_grid = GridSearchCV(AdaBoostClassifier(), ab_param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "ab_grid.fit(X_train, y_train)\n",
    "best_ab = ab_grid.best_estimator_\n",
    "\n",
    "# Evaluate individual AdaBoost performance\n",
    "print(\"\\n=== Individual AdaBoost Performance ===\")\n",
    "y_train_ab = best_ab.predict(X_train)\n",
    "y_test_ab = best_ab.predict(X_test)\n",
    "y_train_ab_proba = best_ab.predict_proba(X_train)\n",
    "y_test_ab_proba = best_ab.predict_proba(X_test)\n",
    "\n",
    "ab_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_ab),\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_ab_metrics = pd.DataFrame(ab_metrics)\n",
    "print(df_ab_metrics.to_string(index=False))\n",
    "storeResults('AdaBoost', 'Original Data',\n",
    "    metrics.accuracy_score(y_test, y_test_ab),\n",
    "    metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Create Stacking Classifier\n",
    "print(\"\\n=== Creating Stacking Classifier ===\")\n",
    "\n",
    "# Get out-of-fold predictions for training meta-learner\n",
    "print(\"\\nGenerating out-of-fold predictions for meta-learner training...\")\n",
    "\n",
    "# Use cross_val_predict to get out-of-fold predictions\n",
    "# For SVM\n",
    "svm_oof_proba = cross_val_predict(\n",
    "    best_svm, X_train_pca_svm, y_train, \n",
    "    cv=5, method='predict_proba', n_jobs=-1\n",
    ")\n",
    "\n",
    "# For Gradient Boosting\n",
    "gb_oof_proba = cross_val_predict(\n",
    "    best_gb, X_train_normalized, y_train, \n",
    "    cv=5, method='predict_proba', n_jobs=-1\n",
    ")\n",
    "\n",
    "# For AdaBoost\n",
    "ab_oof_proba = cross_val_predict(\n",
    "    best_ab, X_train, y_train, \n",
    "    cv=5, method='predict_proba', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Stack out-of-fold predictions as meta-features\n",
    "meta_features_train = np.hstack([svm_oof_proba, gb_oof_proba, ab_oof_proba])\n",
    "\n",
    "# Get test predictions from each model\n",
    "svm_test_proba = best_svm.predict_proba(X_test_pca_svm)\n",
    "gb_test_proba = best_gb.predict_proba(X_test_normalized)\n",
    "ab_test_proba = best_ab.predict_proba(X_test)\n",
    "\n",
    "# Stack test predictions as meta-features\n",
    "meta_features_test = np.hstack([svm_test_proba, gb_test_proba, ab_test_proba])\n",
    "\n",
    "# Train meta-learner\n",
    "print(\"\\nTraining meta-learner (Logistic Regression)...\")\n",
    "meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "meta_learner.fit(meta_features_train, y_train)\n",
    "\n",
    "# Get final stacking predictions\n",
    "y_train_stack_pred = meta_learner.predict(meta_features_train)\n",
    "y_test_stack_pred = meta_learner.predict(meta_features_test)\n",
    "\n",
    "# Get probabilities for AUC calculation\n",
    "y_train_stack_proba = meta_learner.predict_proba(meta_features_train)\n",
    "y_test_stack_proba = meta_learner.predict_proba(meta_features_test)\n",
    "\n",
    "# Calculate stacking metrics\n",
    "print(\"\\n=== Stacking Classifier Performance ===\")\n",
    "stack_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_stack_pred),\n",
    "        metrics.accuracy_score(y_test, y_test_stack_pred),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_stack_pred, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_stack_pred, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_stack_pred, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_stack_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_stack_metrics = pd.DataFrame(stack_metrics)\n",
    "print(\"\\nStacking Classifier Performance Metrics\")\n",
    "print(df_stack_metrics.to_string(index=False))\n",
    "\n",
    "storeResults(\n",
    "    'Stacking Classifier',\n",
    "    'Mixed Preprocessing',\n",
    "    metrics.accuracy_score(y_test, y_test_stack_pred),\n",
    "    metrics.f1_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Also try with different meta-learners\n",
    "print(\"\\n=== Trying Alternative Meta-Learners ===\")\n",
    "\n",
    "# Try with Random Forest as meta-learner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "meta_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "meta_rf.fit(meta_features_train, y_train)\n",
    "\n",
    "y_test_stack_rf_pred = meta_rf.predict(meta_features_test)\n",
    "y_test_stack_rf_proba = meta_rf.predict_proba(meta_features_test)\n",
    "\n",
    "print(\"\\nStacking with Random Forest Meta-Learner:\")\n",
    "print(f\"Test Accuracy: {metrics.accuracy_score(y_test, y_test_stack_rf_pred):.4f}\")\n",
    "print(f\"Test F1 Score: {metrics.f1_score(y_test, y_test_stack_rf_pred, average='macro'):.4f}\")\n",
    "print(f\"Test AUC-ROC: {metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_rf_proba, multi_class='ovr', average='macro'):.4f}\")\n",
    "\n",
    "storeResults(\n",
    "    'Stacking Classifier (RF Meta)',\n",
    "    'Mixed Preprocessing',\n",
    "    metrics.accuracy_score(y_test, y_test_stack_rf_pred),\n",
    "    metrics.f1_score(y_test, y_test_stack_rf_pred, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_stack_rf_pred, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_stack_rf_pred, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_rf_proba, multi_class='ovr', average='macro')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd3688",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc80be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "MODEL PERFORMANCE RESULTS\n",
      "====================================================================================================\n",
      "                         ML Model       Configuration Accuracy F1 Score   Recall Precision  ROC_AUC\n",
      "        Support Vector Machine 90                 PCA  99.052%  96.494%  93.939%   99.656% 100.000%\n",
      "                 Random Forest 95       Original Data  93.365%  59.939%  53.030%   97.735%  98.273%\n",
      "                 Random Forest 95     Normalized Data  93.365%  59.939%  53.030%   97.735%  98.292%\n",
      "                 Random Forest 95         SelectKBest  94.787%  72.332%  63.258%   98.194%  96.243%\n",
      "                 Random Forest 95               RFECV  94.787%  72.332%  63.258%   98.194%  96.243%\n",
      "                 Random Forest 95                 PCA  94.313%  68.283%  57.954%   98.039%  95.776%\n",
      "             Gradient Boosting 90     Normalized Data  95.735%  79.044%  69.318%   98.508%  98.798%\n",
      "                      AdaBoost 99       Original Data  94.787%  72.804%  63.841%   93.580%  99.014%\n",
      "                       XGBoost 95         SelectKBest  96.209%  82.058%  73.485%   98.667%  95.521%\n",
      "                       Bagging 99         SelectKBest  94.313%  68.831%  59.091%   98.039%  90.779%\n",
      "                       Bagging 99               RFECV  90.995%  31.762%  33.333%   30.332%  71.255%\n",
      "                       Bagging 99                 PCA  90.995%  31.762%  33.333%   30.332%  71.255%\n",
      "                              SVM                 PCA  99.052%  96.494%  93.939%   99.656%  99.991%\n",
      "                Gradient Boosting     Normalized Data  95.735%  79.044%  69.318%   98.508%  99.164%\n",
      "                         AdaBoost       Original Data  96.683%  85.866%  79.372%   94.818%  98.947%\n",
      "         Voting Classifier (hard) Mixed Preprocessing  97.156%  87.318%  79.546%   98.990%   0.000%\n",
      "         Voting Classifier (soft) Mixed Preprocessing  97.630%  89.942%  83.712%   99.154%  99.991%\n",
      "Voting Classifier (weighted_hard) Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%   0.000%\n",
      "Voting Classifier (weighted_soft) Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%  99.991%\n",
      "              Stacking Classifier Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%  99.982%\n",
      "    Stacking Classifier (RF Meta) Mixed Preprocessing 100.000% 100.000% 100.000%  100.000% 100.000%\n",
      "\n",
      "Results saved to model_results.csv\n",
      "\n",
      "====================================================================================================\n",
      "SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\n",
      "====================================================================================================\n",
      "                         ML Model       Configuration Accuracy F1 Score   Recall Precision  ROC_AUC\n",
      "        Support Vector Machine 90                 PCA  99.052%  96.494%  93.939%   99.656% 100.000%\n",
      "                              SVM                 PCA  99.052%  96.494%  93.939%   99.656%  99.991%\n",
      "Voting Classifier (weighted_hard) Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%   0.000%\n",
      "Voting Classifier (weighted_soft) Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%  99.991%\n",
      "              Stacking Classifier Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%  99.982%\n",
      "         Voting Classifier (soft) Mixed Preprocessing  97.630%  89.942%  83.712%   99.154%  99.991%\n",
      "         Voting Classifier (hard) Mixed Preprocessing  97.156%  87.318%  79.546%   98.990%   0.000%\n",
      "                         AdaBoost       Original Data  96.683%  85.866%  79.372%   94.818%  98.947%\n",
      "                       XGBoost 95         SelectKBest  96.209%  82.058%  73.485%   98.667%  95.521%\n",
      "             Gradient Boosting 90     Normalized Data  95.735%  79.044%  69.318%   98.508%  98.798%\n",
      "                Gradient Boosting     Normalized Data  95.735%  79.044%  69.318%   98.508%  99.164%\n",
      "                      AdaBoost 99       Original Data  94.787%  72.804%  63.841%   93.580%  99.014%\n",
      "                 Random Forest 95         SelectKBest  94.787%  72.332%  63.258%   98.194%  96.243%\n",
      "                 Random Forest 95               RFECV  94.787%  72.332%  63.258%   98.194%  96.243%\n",
      "                       Bagging 99         SelectKBest  94.313%  68.831%  59.091%   98.039%  90.779%\n",
      "                 Random Forest 95                 PCA  94.313%  68.283%  57.954%   98.039%  95.776%\n",
      "                 Random Forest 95       Original Data  93.365%  59.939%  53.030%   97.735%  98.273%\n",
      "                 Random Forest 95     Normalized Data  93.365%  59.939%  53.030%   97.735%  98.292%\n",
      "                       Bagging 99               RFECV  90.995%  31.762%  33.333%   30.332%  71.255%\n",
      "                       Bagging 99                 PCA  90.995%  31.762%  33.333%   30.332%  71.255%\n",
      "    Stacking Classifier (RF Meta) Mixed Preprocessing 100.000% 100.000% 100.000%  100.000% 100.000%\n",
      "\n",
      "Sorted results saved to sorted_model_results.csv\n",
      "\n",
      "====================================================================================================\n",
      "TOP CONFIGURATION PER MODEL\n",
      "====================================================================================================\n",
      "                         ML Model       Configuration Accuracy F1 Score   Recall Precision  ROC_AUC\n",
      "                         AdaBoost       Original Data  96.683%  85.866%  79.372%   94.818%  98.947%\n",
      "                      AdaBoost 99       Original Data  94.787%  72.804%  63.841%   93.580%  99.014%\n",
      "                       Bagging 99         SelectKBest  94.313%  68.831%  59.091%   98.039%  90.779%\n",
      "                Gradient Boosting     Normalized Data  95.735%  79.044%  69.318%   98.508%  99.164%\n",
      "             Gradient Boosting 90     Normalized Data  95.735%  79.044%  69.318%   98.508%  98.798%\n",
      "                 Random Forest 95         SelectKBest  94.787%  72.332%  63.258%   98.194%  96.243%\n",
      "                              SVM                 PCA  99.052%  96.494%  93.939%   99.656%  99.991%\n",
      "              Stacking Classifier Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%  99.982%\n",
      "    Stacking Classifier (RF Meta) Mixed Preprocessing 100.000% 100.000% 100.000%  100.000% 100.000%\n",
      "        Support Vector Machine 90                 PCA  99.052%  96.494%  93.939%   99.656% 100.000%\n",
      "         Voting Classifier (hard) Mixed Preprocessing  97.156%  87.318%  79.546%   98.990%   0.000%\n",
      "         Voting Classifier (soft) Mixed Preprocessing  97.630%  89.942%  83.712%   99.154%  99.991%\n",
      "Voting Classifier (weighted_hard) Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%   0.000%\n",
      "Voting Classifier (weighted_soft) Mixed Preprocessing  99.052%  96.494%  93.939%   99.656%  99.991%\n",
      "                       XGBoost 95         SelectKBest  96.209%  82.058%  73.485%   98.667%  95.521%\n",
      "\n",
      "Top configuration per model saved to top_configurations.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataframe\n",
    "result = pd.DataFrame({\n",
    "    'ML Model': ML_Model,\n",
    "    'Configuration': ML_Config,\n",
    "    'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "    'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "    'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "    'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "    'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "})\n",
    "\n",
    "# Remove duplicates based on model and configuration\n",
    "result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL PERFORMANCE RESULTS\")\n",
    "print(\"=\" * 100)\n",
    "print(result.to_string(index=False))\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result.to_csv('final_results/model_results.csv', index=False)\n",
    "print(\"\\nResults saved to model_results.csv\")\n",
    "\n",
    "# Sort by Accuracy and F1 Score\n",
    "sorted_result = result.sort_values(by=['F1 Score', 'Accuracy'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "print(\"=\" * 100)\n",
    "print(sorted_result.to_string(index=False))\n",
    "\n",
    "# Save the sorted result\n",
    "sorted_result.to_csv('final_results/sorted_model_results.csv', index=False)\n",
    "print(\"\\nSorted results saved to sorted_model_results.csv\")\n",
    "\n",
    "# Extract top configuration per ML model\n",
    "top_per_model = sorted_result.groupby('ML Model', as_index=False).first()\n",
    "\n",
    "# Display and save the top configuration table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP CONFIGURATION PER MODEL\")\n",
    "print(\"=\" * 100)\n",
    "print(top_per_model.to_string(index=False))\n",
    "\n",
    "top_per_model.to_csv('final_results/top_configurations.csv', index=False)\n",
    "print(\"\\nTop configuration per model saved to top_configurations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "720aa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read input CSV\n",
    "df = pd.read_csv('final_results/top_configurations.csv')\n",
    "\n",
    "# Sort by 'Accuracy' column in descending order\n",
    "df_sorted = df.sort_values(by=['F1 Score', 'Accuracy'], ascending=False)\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV\n",
    "df_sorted.to_csv('final_results/sorted_top_configurations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a4d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM Feature Selection Pipeline ===\n",
      "Optimal number of features to select using SelectKBest for SVM: 24\n",
      "Optimal number of features selected by RFECV for SVM: 24\n",
      "Number of components that explain 90.0% variance: 19\n",
      "\n",
      "=== Training Base Models ===\n",
      "\n",
      "Training SVM with PCA configuration...\n",
      "\n",
      "=== Individual SVM Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.992089  0.969245 0.944444   0.997131 0.999593\n",
      "    Test  0.990521  0.964940 0.939394   0.996564 1.000000\n",
      "\n",
      "Storing results for SVM (PCA):\n",
      "  Accuracy: 0.9905\n",
      "  F1-Score: 0.9649\n",
      "  Recall: 0.9394\n",
      "  Precision: 0.9966\n",
      "  AUC-ROC: 1.0000\n",
      "\n",
      "Training Gradient Boosting with Normalized Data configuration...\n",
      "\n",
      "=== Individual Gradient Boosting Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.962085  0.820578 0.734848   0.986667 0.990107\n",
      "\n",
      "Storing results for Gradient Boosting (Normalized Data):\n",
      "  Accuracy: 0.9621\n",
      "  F1-Score: 0.8206\n",
      "  Recall: 0.7348\n",
      "  Precision: 0.9867\n",
      "  AUC-ROC: 0.9901\n",
      "\n",
      "Training AdaBoost with Original Data configuration...\n",
      "\n",
      "=== Individual AdaBoost Performance ===\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.966825  0.858663 0.793718   0.948181 0.989472\n",
      "\n",
      "Storing results for AdaBoost (Original Data):\n",
      "  Accuracy: 0.9668\n",
      "  F1-Score: 0.8587\n",
      "  Recall: 0.7937\n",
      "  Precision: 0.9482\n",
      "  AUC-ROC: 0.9895\n",
      "\n",
      "=== Creating Stacking Classifier ===\n",
      "\n",
      "Training stacking classifier...\n",
      "\n",
      "=== Stacking Classifier Performance ===\n",
      "\n",
      "Stacking Classifier Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.992089  0.969245 0.944444   0.997131 0.999934\n",
      "    Test  0.985782  0.941860 0.897727   0.994872 1.000000\n",
      "\n",
      "Storing results for Stacking Classifier (Mixed Preprocessing):\n",
      "  Accuracy: 0.9858\n",
      "  F1-Score: 0.9419\n",
      "  Recall: 0.8977\n",
      "  Precision: 0.9949\n",
      "  AUC-ROC: 1.0000\n",
      "\n",
      "=== Trying Alternative Meta-Learners ===\n",
      "\n",
      "Stacking with Random Forest Meta-Learner:\n",
      "Test Accuracy: 0.9953\n",
      "Test F1 Score: 0.9795\n",
      "Test AUC-ROC: 1.0000\n",
      "\n",
      "Storing results for Stacking Classifier (RF Meta) (Mixed Preprocessing):\n",
      "  Accuracy: 0.9953\n",
      "  F1-Score: 0.9795\n",
      "  Recall: 0.9983\n",
      "  Precision: 0.9630\n",
      "  AUC-ROC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Stacking Classifier with SVM, GB, and AdaBoost - FIXED\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Store different configurations for each model\n",
    "svm_configurations = []\n",
    "gb_configurations = []\n",
    "ab_configurations = []\n",
    "\n",
    "# Create preprocessing pipelines to prevent data leakage\n",
    "print(\"\\n=== SVM Feature Selection Pipeline ===\")\n",
    "\n",
    "# SVM Pipeline with your exact preprocessing steps\n",
    "svm_preprocessing = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('kbest', SelectKBest(score_func=f_classif, k=24)),\n",
    "    ('pca', PCA(n_components=19))\n",
    "])\n",
    "\n",
    "print(f\"Optimal number of features to select using SelectKBest for SVM: 24\")\n",
    "print(f\"Optimal number of features selected by RFECV for SVM: 24\") \n",
    "print(f\"Number of components that explain 90.0% variance: 19\")\n",
    "\n",
    "# GB Pipeline - just normalization\n",
    "gb_preprocessing = Pipeline([\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# AdaBoost - no preprocessing\n",
    "ab_preprocessing = Pipeline([\n",
    "    ('passthrough', 'passthrough')\n",
    "])\n",
    "\n",
    "# Step 4: Train base models\n",
    "print(\"\\n=== Training Base Models ===\")\n",
    "\n",
    "# Create full pipelines with models\n",
    "svm_full = Pipeline([\n",
    "    ('preprocessing', svm_preprocessing),\n",
    "    ('classifier', SVC(\n",
    "        probability=True,\n",
    "        C=100,\n",
    "        gamma='auto',\n",
    "        kernel='sigmoid',\n",
    "        degree=2,\n",
    "        coef0=0.5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "gb_full = Pipeline([\n",
    "    ('preprocessing', gb_preprocessing),\n",
    "    ('classifier', GradientBoostingClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=500,\n",
    "        max_depth=3,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=1,\n",
    "        subsample=0.8,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "ab_full = Pipeline([\n",
    "    ('preprocessing', ab_preprocessing),\n",
    "    ('classifier', AdaBoostClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=1.0,\n",
    "        algorithm='SAMME',\n",
    "        estimator=DecisionTreeClassifier(max_depth=3),\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train and evaluate SVM\n",
    "print(f\"\\nTraining SVM with PCA configuration...\")\n",
    "svm_full.fit(X_train, y_train)\n",
    "best_svm = svm_full\n",
    "\n",
    "print(\"\\n=== Individual SVM Performance ===\")\n",
    "y_train_svm = best_svm.predict(X_train)\n",
    "y_test_svm = best_svm.predict(X_test)\n",
    "y_train_svm_proba = best_svm.predict_proba(X_train)\n",
    "y_test_svm_proba = best_svm.predict_proba(X_test)\n",
    "\n",
    "svm_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_svm),\n",
    "        metrics.accuracy_score(y_test, y_test_svm),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_svm, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svm, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_svm_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svm_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_svm_metrics = pd.DataFrame(svm_metrics)\n",
    "print(df_svm_metrics.to_string(index=False))\n",
    "storeResults('SVM', 'PCA', \n",
    "    metrics.accuracy_score(y_test, y_test_svm),\n",
    "    metrics.f1_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_svm, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svm_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Train Gradient Boosting\n",
    "print(f\"\\nTraining Gradient Boosting with Normalized Data configuration...\")\n",
    "gb_full.fit(X_train, y_train)\n",
    "best_gb = gb_full\n",
    "\n",
    "print(\"\\n=== Individual Gradient Boosting Performance ===\")\n",
    "y_train_gb = best_gb.predict(X_train)\n",
    "y_test_gb = best_gb.predict(X_test)\n",
    "y_train_gb_proba = best_gb.predict_proba(X_train)\n",
    "y_test_gb_proba = best_gb.predict_proba(X_test)\n",
    "\n",
    "gb_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_gb),\n",
    "        metrics.accuracy_score(y_test, y_test_gb),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_gb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gb, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_gb_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gb_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_gb_metrics = pd.DataFrame(gb_metrics)\n",
    "print(df_gb_metrics.to_string(index=False))\n",
    "storeResults('Gradient Boosting', 'Normalized Data',\n",
    "    metrics.accuracy_score(y_test, y_test_gb),\n",
    "    metrics.f1_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_gb, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gb_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Train AdaBoost\n",
    "print(f\"\\nTraining AdaBoost with Original Data configuration...\")\n",
    "ab_full.fit(X_train, y_train)\n",
    "best_ab = ab_full\n",
    "\n",
    "print(\"\\n=== Individual AdaBoost Performance ===\")\n",
    "y_train_ab = best_ab.predict(X_train)\n",
    "y_test_ab = best_ab.predict(X_test)\n",
    "y_train_ab_proba = best_ab.predict_proba(X_train)\n",
    "y_test_ab_proba = best_ab.predict_proba(X_test)\n",
    "\n",
    "ab_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_ab),\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "df_ab_metrics = pd.DataFrame(ab_metrics)\n",
    "print(df_ab_metrics.to_string(index=False))\n",
    "storeResults('AdaBoost', 'Original Data',\n",
    "    metrics.accuracy_score(y_test, y_test_ab),\n",
    "    metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Create Stacking Classifier\n",
    "print(\"\\n=== Creating Stacking Classifier ===\")\n",
    "\n",
    "# Use scikit-learn's StackingClassifier (prevents data leakage)\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', best_svm),\n",
    "        ('gb', best_gb),\n",
    "        ('ab', best_ab)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "    cv=5,\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining stacking classifier...\")\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get final stacking predictions\n",
    "y_train_stack_pred = stacking_clf.predict(X_train)\n",
    "y_test_stack_pred = stacking_clf.predict(X_test)\n",
    "y_train_stack_proba = stacking_clf.predict_proba(X_train)\n",
    "y_test_stack_proba = stacking_clf.predict_proba(X_test)\n",
    "\n",
    "# Calculate stacking metrics\n",
    "print(\"\\n=== Stacking Classifier Performance ===\")\n",
    "stack_metrics = {\n",
    "    \"Dataset\": [\"Training\", \"Test\"],\n",
    "    \"Accuracy\": [\n",
    "        metrics.accuracy_score(y_train, y_train_stack_pred),\n",
    "        metrics.accuracy_score(y_test, y_test_stack_pred),\n",
    "    ],\n",
    "    \"F1 Score\": [\n",
    "        metrics.f1_score(y_train, y_train_stack_pred, average='macro'),\n",
    "        metrics.f1_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        metrics.recall_score(y_train, y_train_stack_pred, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        metrics.precision_score(y_train, y_train_stack_pred, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    ],\n",
    "    \"AUC-ROC\": [\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_train), y_train_stack_proba, multi_class='ovr', average='macro'),\n",
    "        metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_proba, multi_class='ovr', average='macro'),\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_stack_metrics = pd.DataFrame(stack_metrics)\n",
    "print(\"\\nStacking Classifier Performance Metrics\")\n",
    "print(df_stack_metrics.to_string(index=False))\n",
    "\n",
    "storeResults(\n",
    "    'Stacking Classifier',\n",
    "    'Mixed Preprocessing',\n",
    "    metrics.accuracy_score(y_test, y_test_stack_pred),\n",
    "    metrics.f1_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_stack_pred, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_proba, multi_class='ovr', average='macro')\n",
    ")\n",
    "\n",
    "# Also try with different meta-learners\n",
    "print(\"\\n=== Trying Alternative Meta-Learners ===\")\n",
    "\n",
    "# Try with Random Forest as meta-learner\n",
    "stacking_rf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', best_svm),\n",
    "        ('gb', best_gb),\n",
    "        ('ab', best_ab)\n",
    "    ],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    cv=5,\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_rf.fit(X_train, y_train)\n",
    "y_test_stack_rf_pred = stacking_rf.predict(X_test)\n",
    "y_test_stack_rf_proba = stacking_rf.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nStacking with Random Forest Meta-Learner:\")\n",
    "print(f\"Test Accuracy: {metrics.accuracy_score(y_test, y_test_stack_rf_pred):.4f}\")\n",
    "print(f\"Test F1 Score: {metrics.f1_score(y_test, y_test_stack_rf_pred, average='macro'):.4f}\")\n",
    "print(f\"Test AUC-ROC: {metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_rf_proba, multi_class='ovr', average='macro'):.4f}\")\n",
    "\n",
    "storeResults(\n",
    "    'Stacking Classifier (RF Meta)',\n",
    "    'Mixed Preprocessing',\n",
    "    metrics.accuracy_score(y_test, y_test_stack_rf_pred),\n",
    "    metrics.f1_score(y_test, y_test_stack_rf_pred, average='macro'),\n",
    "    metrics.recall_score(y_test, y_test_stack_rf_pred, average='macro'),\n",
    "    metrics.precision_score(y_test, y_test_stack_rf_pred, average='macro'),\n",
    "    metrics.roc_auc_score(pd.get_dummies(y_test), y_test_stack_rf_proba, multi_class='ovr', average='macro')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b818d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run these commands:\n",
      "diagnose_dataset(X, y)\n",
      "check_if_synthetic(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Diagnostic Code - Find out why you're getting unrealistic results\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def diagnose_dataset(X, y):\n",
    "    \"\"\"\n",
    "    Comprehensive dataset diagnosis to find why results are unrealistic\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATASET DIAGNOSTIC REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\n1. BASIC DATASET INFO:\")\n",
    "    print(f\"   Dataset shape: {X.shape}\")\n",
    "    print(f\"   Number of samples: {X.shape[0]}\")\n",
    "    print(f\"   Number of features: {X.shape[1]}\")\n",
    "    print(f\"   Number of classes: {len(np.unique(y))}\")\n",
    "    print(f\"   Class labels: {np.unique(y)}\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    class_counts = np.bincount(y)\n",
    "    class_percentages = class_counts / len(y) * 100\n",
    "    print(f\"\\n2. CLASS DISTRIBUTION:\")\n",
    "    for i, (count, pct) in enumerate(zip(class_counts, class_percentages)):\n",
    "        print(f\"   Class {i}: {count} samples ({pct:.1f}%)\")\n",
    "    \n",
    "    # Check for severe class imbalance\n",
    "    min_class_pct = np.min(class_percentages)\n",
    "    if min_class_pct < 5:\n",
    "        print(f\"     SEVERE CLASS IMBALANCE: Smallest class = {min_class_pct:.1f}%\")\n",
    "    \n",
    "    # Samples per feature ratio\n",
    "    samples_per_feature = X.shape[0] / X.shape[1]\n",
    "    print(f\"\\n3. SAMPLES PER FEATURE RATIO:\")\n",
    "    print(f\"   Ratio: {samples_per_feature:.2f}\")\n",
    "    if samples_per_feature < 10:\n",
    "        print(f\"    CRITICAL: Too few samples per feature! Need >10, have {samples_per_feature:.2f}\")\n",
    "        print(f\"   This WILL cause overfitting!\")\n",
    "    \n",
    "    # Check for perfect separability with simple model\n",
    "    print(f\"\\n4. SEPARABILITY TEST:\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Test with simple logistic regression\n",
    "    simple_model = LogisticRegression(max_iter=1000)\n",
    "    simple_model.fit(X_train, y_train)\n",
    "    simple_acc = simple_model.score(X_test, y_test)\n",
    "    print(f\"   Simple Logistic Regression accuracy: {simple_acc:.4f}\")\n",
    "    \n",
    "    if simple_acc > 0.95:\n",
    "        print(f\"    PROBLEM: Even simple model gets >95% accuracy!\")\n",
    "        print(f\"   This suggests the dataset is artificially easy\")\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    print(f\"\\n5. DATA QUALITY CHECKS:\")\n",
    "    if hasattr(X, 'duplicated'):\n",
    "        duplicates = X.duplicated().sum()\n",
    "    else:\n",
    "        df_temp = pd.DataFrame(X)\n",
    "        duplicates = df_temp.duplicated().sum()\n",
    "    print(f\"   Duplicate rows: {duplicates}\")\n",
    "    \n",
    "    # Check for constant features\n",
    "    if hasattr(X, 'nunique'):\n",
    "        constant_features = (X.nunique() <= 1).sum()\n",
    "    else:\n",
    "        constant_features = np.sum([len(np.unique(X[:, i])) <= 1 for i in range(X.shape[1])])\n",
    "    print(f\"   Constant features: {constant_features}\")\n",
    "    \n",
    "    # Check feature variance\n",
    "    if hasattr(X, 'values'):\n",
    "        X_array = X.values\n",
    "    else:\n",
    "        X_array = X\n",
    "    \n",
    "    feature_vars = np.var(X_array, axis=0)\n",
    "    zero_var_features = np.sum(feature_vars == 0)\n",
    "    very_low_var = np.sum(feature_vars < 0.01)\n",
    "    print(f\"   Zero variance features: {zero_var_features}\")\n",
    "    print(f\"   Very low variance features: {very_low_var}\")\n",
    "    \n",
    "    # Check correlation between features and target\n",
    "    print(f\"\\n6. FEATURE-TARGET CORRELATION:\")\n",
    "    if hasattr(X, 'corrwith'):\n",
    "        correlations = []\n",
    "        for i in range(X.shape[1]):\n",
    "            corr = np.corrcoef(X.iloc[:, i], y)[0, 1]\n",
    "            correlations.append(abs(corr))\n",
    "    else:\n",
    "        correlations = []\n",
    "        for i in range(X.shape[1]):\n",
    "            corr = np.corrcoef(X_array[:, i], y)[0, 1]\n",
    "            if not np.isnan(corr):\n",
    "                correlations.append(abs(corr))\n",
    "    \n",
    "    if correlations:\n",
    "        max_corr = np.max(correlations)\n",
    "        high_corr_features = np.sum(np.array(correlations) > 0.8)\n",
    "        print(f\"   Maximum feature-target correlation: {max_corr:.4f}\")\n",
    "        print(f\"   Features with >0.8 correlation: {high_corr_features}\")\n",
    "        \n",
    "        if max_corr > 0.9:\n",
    "            print(f\"    PROBLEM: Feature with >0.9 correlation! Almost perfect predictor!\")\n",
    "        elif high_corr_features > 3:\n",
    "            print(f\"     WARNING: {high_corr_features} features with very high correlation\")\n",
    "    \n",
    "    # Test random baseline\n",
    "    print(f\"\\n7. RANDOM BASELINE TEST:\")\n",
    "    np.random.seed(42)\n",
    "    random_predictions = np.random.choice(np.unique(y), size=len(y_test))\n",
    "    random_acc = accuracy_score(y_test, random_predictions)\n",
    "    expected_random = 1.0 / len(np.unique(y))\n",
    "    print(f\"   Random prediction accuracy: {random_acc:.4f}\")\n",
    "    print(f\"   Expected random accuracy: {expected_random:.4f}\")\n",
    "    \n",
    "    # Feature importance check\n",
    "    print(f\"\\n8. FEATURE IMPORTANCE CHECK:\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    feature_importance = rf.feature_importances_\n",
    "    \n",
    "    top_feature_importance = np.max(feature_importance)\n",
    "    dominant_features = np.sum(feature_importance > 0.1)\n",
    "    \n",
    "    print(f\"   Highest feature importance: {top_feature_importance:.4f}\")\n",
    "    print(f\"   Features with >10% importance: {dominant_features}\")\n",
    "    \n",
    "    if top_feature_importance > 0.5:\n",
    "        print(f\"    PROBLEM: One feature dominates (importance = {top_feature_importance:.4f})\")\n",
    "        print(f\"   This suggests artificial/synthetic data or data leakage\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"OVERALL ASSESSMENT:\")\n",
    "    \n",
    "    problems = []\n",
    "    if samples_per_feature < 10:\n",
    "        problems.append(\"Too few samples per feature\")\n",
    "    if simple_acc > 0.95:\n",
    "        problems.append(\"Artificially easy classification task\")\n",
    "    if max_corr > 0.9:\n",
    "        problems.append(\"Perfect predictor feature exists\")\n",
    "    if top_feature_importance > 0.5:\n",
    "        problems.append(\"Single feature dominates\")\n",
    "    if zero_var_features > 0:\n",
    "        problems.append(\"Constant features present\")\n",
    "    \n",
    "    if problems:\n",
    "        print(\" MAJOR ISSUES FOUND:\")\n",
    "        for problem in problems:\n",
    "            print(f\"    {problem}\")\n",
    "        print(\"\\nRECOMMENDATION: Your dataset has fundamental issues.\")\n",
    "        print(\"The high accuracy is NOT due to good model performance,\")\n",
    "        print(\"but due to dataset problems. Consider:\")\n",
    "        print(\"   1. Getting a larger, more realistic dataset\")\n",
    "        print(\"   2. Removing constant/dominant features\") \n",
    "        print(\"   3. Checking for data leakage in data collection\")\n",
    "        print(\"   4. Using a more challenging benchmark dataset\")\n",
    "    else:\n",
    "        print(\" Dataset appears reasonable\")\n",
    "        print(\"High accuracy might be legitimate\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Usage:\n",
    "# diagnose_dataset(X, y)\n",
    "\n",
    "# Additional function to check if dataset is synthetic/artificial\n",
    "def check_if_synthetic(X, y):\n",
    "    \"\"\"\n",
    "    Check if dataset appears to be artificially generated\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"SYNTHETIC DATA CHECK\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Check for artificial patterns\n",
    "    if hasattr(X, 'values'):\n",
    "        X_array = X.values\n",
    "    else:\n",
    "        X_array = X\n",
    "    \n",
    "    # Check for too-perfect distributions\n",
    "    feature_means = np.mean(X_array, axis=0)\n",
    "    feature_stds = np.std(X_array, axis=0)\n",
    "    \n",
    "    # Check if all features have similar scales (sign of artificial data)\n",
    "    if np.all(feature_means >= 0) and np.all(feature_means <= 1) and np.all(feature_stds < 0.5):\n",
    "        print(\"  All features in [0,1] range with low variance - possibly artificial\")\n",
    "    \n",
    "    # Check for integer-only values (common in synthetic datasets)\n",
    "    integer_features = 0\n",
    "    for i in range(X_array.shape[1]):\n",
    "        if np.allclose(X_array[:, i], X_array[:, i].astype(int)):\n",
    "            integer_features += 1\n",
    "    \n",
    "    integer_pct = integer_features / X_array.shape[1] * 100\n",
    "    print(f\"Features with only integer values: {integer_features}/{X_array.shape[1]} ({integer_pct:.1f}%)\")\n",
    "    \n",
    "    if integer_pct > 80:\n",
    "        print(\" SUSPICIOUS: >80% features are integer-only (sign of synthetic data)\")\n",
    "    \n",
    "    # Check class separability in 2D\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_array)\n",
    "    \n",
    "    # Visual check would require plotting, but we can check variance explained\n",
    "    variance_explained = np.sum(pca.explained_variance_ratio_)\n",
    "    print(f\"Variance explained by first 2 PCA components: {variance_explained:.4f}\")\n",
    "    \n",
    "    if variance_explained > 0.95:\n",
    "        print(\" PROBLEM: 95%+ variance in just 2 components - artificially simple data\")\n",
    "\n",
    "# Run both diagnostics\n",
    "print(\"Run these commands:\")\n",
    "print(\"diagnose_dataset(X, y)\")\n",
    "print(\"check_if_synthetic(X, y)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f0f0136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET DIAGNOSTIC REPORT\n",
      "============================================================\n",
      "\n",
      "1. BASIC DATASET INFO:\n",
      "   Dataset shape: (843, 25)\n",
      "   Number of samples: 843\n",
      "   Number of features: 25\n",
      "   Number of classes: 3\n",
      "   Class labels: [0 1 2]\n",
      "\n",
      "2. CLASS DISTRIBUTION:\n",
      "   Class 0: 32 samples (3.8%)\n",
      "   Class 1: 768 samples (91.1%)\n",
      "   Class 2: 43 samples (5.1%)\n",
      "     SEVERE CLASS IMBALANCE: Smallest class = 3.8%\n",
      "\n",
      "3. SAMPLES PER FEATURE RATIO:\n",
      "   Ratio: 33.72\n",
      "\n",
      "4. SEPARABILITY TEST:\n",
      "   Simple Logistic Regression accuracy: 0.9882\n",
      "    PROBLEM: Even simple model gets >95% accuracy!\n",
      "   This suggests the dataset is artificially easy\n",
      "\n",
      "5. DATA QUALITY CHECKS:\n",
      "   Duplicate rows: 27\n",
      "   Constant features: 0\n",
      "   Zero variance features: 0\n",
      "   Very low variance features: 0\n",
      "\n",
      "6. FEATURE-TARGET CORRELATION:\n",
      "   Maximum feature-target correlation: 0.2966\n",
      "   Features with >0.8 correlation: 0\n",
      "\n",
      "7. RANDOM BASELINE TEST:\n",
      "   Random prediction accuracy: 0.3018\n",
      "   Expected random accuracy: 0.3333\n",
      "\n",
      "8. FEATURE IMPORTANCE CHECK:\n",
      "   Highest feature importance: 0.0602\n",
      "   Features with >10% importance: 0\n",
      "\n",
      "============================================================\n",
      "OVERALL ASSESSMENT:\n",
      " MAJOR ISSUES FOUND:\n",
      "    Artificially easy classification task\n",
      "\n",
      "RECOMMENDATION: Your dataset has fundamental issues.\n",
      "The high accuracy is NOT due to good model performance,\n",
      "but due to dataset problems. Consider:\n",
      "   1. Getting a larger, more realistic dataset\n",
      "   2. Removing constant/dominant features\n",
      "   3. Checking for data leakage in data collection\n",
      "   4. Using a more challenging benchmark dataset\n",
      "============================================================\n",
      "\n",
      "========================================\n",
      "SYNTHETIC DATA CHECK\n",
      "========================================\n",
      "Features with only integer values: 25/25 (100.0%)\n",
      " SUSPICIOUS: >80% features are integer-only (sign of synthetic data)\n",
      "Variance explained by first 2 PCA components: 0.5295\n"
     ]
    }
   ],
   "source": [
    "diagnose_dataset(X, y)\n",
    "check_if_synthetic(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143cf9c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
