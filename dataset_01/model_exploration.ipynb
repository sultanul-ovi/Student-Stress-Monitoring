{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46073c67",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb398a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af20dae",
   "metadata": {},
   "source": [
    "## ML Model Results Storage Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a95e6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results storage framework loaded successfully!\n",
      "Available functions:\n",
      "- storeResults(model, config, accuracy, f1, recall, precision, auc_roc)\n",
      "- displayAndSaveResults(filename_prefix='model_results')\n",
      "- clearResults()\n",
      "- plotModelComparison(result_df)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ML MODEL RESULTS STORAGE FRAMEWORK\n",
    "# =============================================================================\n",
    "\n",
    "# Creating holders to store the model performance results\n",
    "ML_Model = []\n",
    "ML_Config = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "auc_roc = []  # Adding a holder for AUC-ROC\n",
    "\n",
    "# Function to call for storing the results\n",
    "def storeResults(model, config, a, b, c, d, e):\n",
    "    \"\"\"\n",
    "    Store model performance results\n",
    "    \n",
    "    Parameters:\n",
    "    model: Name of the ML model\n",
    "    config: Configuration name (preprocessing steps applied)\n",
    "    a: Accuracy score\n",
    "    b: F1 score\n",
    "    c: Recall score\n",
    "    d: Precision score\n",
    "    e: AUC-ROC score\n",
    "    \"\"\"\n",
    "    ML_Model.append(model)\n",
    "    ML_Config.append(config)\n",
    "    accuracy.append(round(a, 6))\n",
    "    f1_score.append(round(b, 6))\n",
    "    recall.append(round(c, 6))\n",
    "    precision.append(round(d, 6))\n",
    "    auc_roc.append(round(e, 6))\n",
    "\n",
    "# Function to display and save results\n",
    "def displayAndSaveResults(filename_prefix='model_results'):\n",
    "    \"\"\"\n",
    "    Create dataframe from results, display, and save to CSV\n",
    "    \n",
    "    Parameters:\n",
    "    filename_prefix: Prefix for the CSV filenames\n",
    "    \"\"\"\n",
    "    # Creating the dataframe\n",
    "    result = pd.DataFrame({\n",
    "        'ML Model': ML_Model,\n",
    "        'Configuration': ML_Config,\n",
    "        'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "        'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "        'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "        'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "        'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "    })\n",
    "    \n",
    "    # Remove duplicates if any\n",
    "    result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL PERFORMANCE RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    print(result.to_string(index=False))\n",
    "    \n",
    "    # Saving the result to a CSV file\n",
    "    result.to_csv(f'{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nResults saved to {filename_prefix}.csv\")\n",
    "    \n",
    "    # Sorting the dataframe on accuracy and F1 Score\n",
    "    sorted_result = result.sort_values(by=['Accuracy', 'F1 Score'], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "    print(\"=\"*100)\n",
    "    print(sorted_result.to_string(index=False))\n",
    "    \n",
    "    # Saving the sorted result to a CSV file\n",
    "    sorted_result.to_csv(f'sorted_{filename_prefix}.csv', index=False)\n",
    "    print(f\"\\nSorted results saved to sorted_{filename_prefix}.csv\")\n",
    "    \n",
    "    return result, sorted_result\n",
    "\n",
    "# Function to clear results (useful when running multiple experiments)\n",
    "def clearResults():\n",
    "    \"\"\"Clear all stored results\"\"\"\n",
    "    global ML_Model, ML_Config, accuracy, f1_score, recall, precision, auc_roc\n",
    "    ML_Model.clear()\n",
    "    ML_Config.clear()\n",
    "    accuracy.clear()\n",
    "    f1_score.clear()\n",
    "    recall.clear()\n",
    "    precision.clear()\n",
    "    auc_roc.clear()\n",
    "    print(\"Results cleared!\")\n",
    "\n",
    "# Function to plot model comparison\n",
    "def plotModelComparison(result_df):\n",
    "    \"\"\"\n",
    "    Create visualization comparing model performances\n",
    "    \n",
    "    Parameters:\n",
    "    result_df: DataFrame with model results\n",
    "    \"\"\"\n",
    "    # Convert percentage strings back to floats for plotting\n",
    "    metrics_cols = ['Accuracy', 'F1 Score', 'Recall', 'Precision', 'ROC_AUC']\n",
    "    plot_df = result_df.copy()\n",
    "    \n",
    "    for col in metrics_cols:\n",
    "        plot_df[col] = plot_df[col].str.rstrip('%').astype(float)\n",
    "    \n",
    "    # Create subplot for each metric\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_cols):\n",
    "        # Group by model and get mean performance across configurations\n",
    "        model_performance = plot_df.groupby('ML Model')[metric].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Create bar plot\n",
    "        ax = axes[idx]\n",
    "        bars = ax.bar(range(len(model_performance)), model_performance.values, \n",
    "                      color=plt.cm.Blues(np.linspace(0.4, 0.9, len(model_performance))))\n",
    "        ax.set_xticks(range(len(model_performance)))\n",
    "        ax.set_xticklabels(model_performance.index, rotation=45, ha='right')\n",
    "        ax.set_ylabel(f'{metric} (%)')\n",
    "        ax.set_title(f'Average {metric} by Model', fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # Hide the last subplot if we have 5 metrics\n",
    "    if len(metrics_cols) == 5:\n",
    "        axes[5].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Model results storage framework loaded successfully!\")\n",
    "print(\"Available functions:\")\n",
    "print(\"- storeResults(model, config, accuracy, f1, recall, precision, auc_roc)\")\n",
    "print(\"- displayAndSaveResults(filename_prefix='model_results')\")\n",
    "print(\"- clearResults()\")\n",
    "print(\"- plotModelComparison(result_df)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28c6989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('StressLevelDataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c849cf",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703b85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 19\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV: 19\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 15\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with Original Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.889697  0.891052 0.889017   0.905546 0.987801\n",
      "    Test  0.901818  0.902583 0.903282   0.910426 0.989533\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 0.1, 'coef0': 0.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Running SVM with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.872727  0.872769 0.872979   0.873092 0.972936\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 1.0, 'degree': 4, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997836\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.971000\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with RFECV configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997872\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970353\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.880000  0.881269 0.879410   0.887602 0.924144\n",
      "    Test  0.901818  0.902473 0.902495   0.907805 0.940665\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61756ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 19\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV: 19\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 11\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with Original Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.889697  0.891052 0.889017   0.905546 0.987799\n",
      "    Test  0.901818  0.902583 0.903282   0.910426 0.989453\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 0.1, 'coef0': 0.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Running SVM with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.872727  0.872769 0.872979   0.873092 0.972938\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 1.0, 'degree': 4, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997877\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970615\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with RFECV configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997930\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970434\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.887273  0.887732 0.887622   0.888524 0.979593\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 10, 'coef0': 0.5, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ea0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 19\n",
      "\n",
      "=== RFECV Feature Selection with SVM ===\n",
      "Optimal number of features selected by RFECV: 19\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 18\n",
      "\n",
      "=== SVM Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running SVM with Original Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.889697  0.891052 0.889017   0.905546 0.987804\n",
      "    Test  0.901818  0.902583 0.903282   0.910426 0.989512\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 0.1, 'coef0': 0.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Running SVM with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.872727  0.872769 0.872979   0.873092 0.973307\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 1.0, 'degree': 4, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848  0.99781\n",
      "    Test  0.890909  0.891334 0.891195   0.891887  0.96983\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with RFECV configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.963636  0.963723 0.963629   0.963848 0.997835\n",
      "    Test  0.890909  0.891334 0.891195   0.891887 0.970087\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Running SVM with PCA configuration...\n",
      "Fitting 10 folds for each of 900 candidates, totalling 9000 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.909091  0.909390 0.909065   0.910020 0.978783\n",
      "    Test  0.905455  0.905573 0.905509   0.905671 0.970683\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 100, 'coef0': 0.0, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your dataset (assuming you've already loaded it as 'data2')\n",
    "X = df.drop(columns=[\"stress_level\"])\n",
    "y = df[\"stress_level\"]\n",
    "\n",
    "# Step 1: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: SVM + GridSearchCV\n",
    "print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "    svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_svc = svc.predict(X_train_cfg)\n",
    "    y_test_svc = svc.predict(X_test_cfg)\n",
    "    y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "    y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "            metrics.accuracy_score(y_test, y_test_svc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Support Vector Machine 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_svc),\n",
    "        metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78501f2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b06ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14f035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066459e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30fd3688",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc80be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "MODEL PERFORMANCE RESULTS\n",
      "====================================================================================================\n",
      "                 ML Model   Configuration Accuracy F1 Score  Recall Precision ROC_AUC\n",
      "Support Vector Machine 95   Original Data  90.182%  90.258% 90.328%   91.043% 98.953%\n",
      "Support Vector Machine 95 Normalized Data  87.273%  87.277% 87.298%   87.309% 97.294%\n",
      "Support Vector Machine 95     SelectKBest  89.091%  89.133% 89.120%   89.189% 97.100%\n",
      "Support Vector Machine 95           RFECV  89.091%  89.133% 89.120%   89.189% 97.035%\n",
      "Support Vector Machine 95             PCA  90.182%  90.247% 90.250%   90.781% 94.066%\n",
      "Support Vector Machine 90   Original Data  90.182%  90.258% 90.328%   91.043% 98.945%\n",
      "Support Vector Machine 90 Normalized Data  87.273%  87.277% 87.298%   87.309% 97.294%\n",
      "Support Vector Machine 90     SelectKBest  89.091%  89.133% 89.120%   89.189% 97.061%\n",
      "Support Vector Machine 90           RFECV  89.091%  89.133% 89.120%   89.189% 97.043%\n",
      "Support Vector Machine 90             PCA  88.727%  88.773% 88.762%   88.852% 97.959%\n",
      "Support Vector Machine 99   Original Data  90.182%  90.258% 90.328%   91.043% 98.951%\n",
      "Support Vector Machine 99 Normalized Data  87.273%  87.277% 87.298%   87.309% 97.331%\n",
      "Support Vector Machine 99     SelectKBest  89.091%  89.133% 89.120%   89.189% 96.983%\n",
      "Support Vector Machine 99           RFECV  89.091%  89.133% 89.120%   89.189% 97.009%\n",
      "Support Vector Machine 99             PCA  90.546%  90.557% 90.551%   90.567% 97.068%\n",
      "\n",
      "Results saved to model_results6.csv\n",
      "\n",
      "====================================================================================================\n",
      "SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\n",
      "====================================================================================================\n",
      "                 ML Model   Configuration Accuracy F1 Score  Recall Precision ROC_AUC\n",
      "Support Vector Machine 99             PCA  90.546%  90.557% 90.551%   90.567% 97.068%\n",
      "Support Vector Machine 95   Original Data  90.182%  90.258% 90.328%   91.043% 98.953%\n",
      "Support Vector Machine 90   Original Data  90.182%  90.258% 90.328%   91.043% 98.945%\n",
      "Support Vector Machine 99   Original Data  90.182%  90.258% 90.328%   91.043% 98.951%\n",
      "Support Vector Machine 95             PCA  90.182%  90.247% 90.250%   90.781% 94.066%\n",
      "Support Vector Machine 95     SelectKBest  89.091%  89.133% 89.120%   89.189% 97.100%\n",
      "Support Vector Machine 95           RFECV  89.091%  89.133% 89.120%   89.189% 97.035%\n",
      "Support Vector Machine 90     SelectKBest  89.091%  89.133% 89.120%   89.189% 97.061%\n",
      "Support Vector Machine 90           RFECV  89.091%  89.133% 89.120%   89.189% 97.043%\n",
      "Support Vector Machine 99     SelectKBest  89.091%  89.133% 89.120%   89.189% 96.983%\n",
      "Support Vector Machine 99           RFECV  89.091%  89.133% 89.120%   89.189% 97.009%\n",
      "Support Vector Machine 90             PCA  88.727%  88.773% 88.762%   88.852% 97.959%\n",
      "Support Vector Machine 95 Normalized Data  87.273%  87.277% 87.298%   87.309% 97.294%\n",
      "Support Vector Machine 90 Normalized Data  87.273%  87.277% 87.298%   87.309% 97.294%\n",
      "Support Vector Machine 99 Normalized Data  87.273%  87.277% 87.298%   87.309% 97.331%\n",
      "\n",
      "Sorted results saved to sorted_model_results6.csv\n",
      "\n",
      "====================================================================================================\n",
      "TOP CONFIGURATION PER MODEL\n",
      "====================================================================================================\n",
      "                 ML Model Configuration Accuracy F1 Score  Recall Precision ROC_AUC\n",
      "Support Vector Machine 90 Original Data  90.182%  90.258% 90.328%   91.043% 98.945%\n",
      "Support Vector Machine 95 Original Data  90.182%  90.258% 90.328%   91.043% 98.953%\n",
      "Support Vector Machine 99           PCA  90.546%  90.557% 90.551%   90.567% 97.068%\n",
      "\n",
      "Top configuration per model saved to top_configurations.csv\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, create and save model performance summary table\n",
    "\n",
    "# Creating the dataframe\n",
    "result = pd.DataFrame({\n",
    "    'ML Model': ML_Model,\n",
    "    'Configuration': ML_Config,\n",
    "    'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "    'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "    'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "    'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "    'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "})\n",
    "\n",
    "# Remove duplicates based on model and configuration\n",
    "result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL PERFORMANCE RESULTS\")\n",
    "print(\"=\" * 100)\n",
    "print(result.to_string(index=False))\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result.to_csv('model_results6.csv', index=False)\n",
    "print(\"\\nResults saved to model_results6.csv\")\n",
    "\n",
    "# Sort by Accuracy and F1 Score\n",
    "sorted_result = result.sort_values(by=['Accuracy', 'F1 Score'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "print(\"=\" * 100)\n",
    "print(sorted_result.to_string(index=False))\n",
    "\n",
    "# Save the sorted result\n",
    "sorted_result.to_csv('sorted_model_results6.csv', index=False)\n",
    "print(\"\\nSorted results saved to sorted_model_results6.csv\")\n",
    "\n",
    "# Extract top configuration per ML model\n",
    "top_per_model = sorted_result.groupby('ML Model', as_index=False).first()\n",
    "\n",
    "# Display and save the top configuration table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP CONFIGURATION PER MODEL\")\n",
    "print(\"=\" * 100)\n",
    "print(top_per_model.to_string(index=False))\n",
    "\n",
    "top_per_model.to_csv('top_configurations.csv', index=False)\n",
    "print(\"\\nTop configuration per model saved to top_configurations.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
